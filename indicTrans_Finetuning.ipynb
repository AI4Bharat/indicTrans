{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "indicTrans_Finetuning.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyM1fXWZfriJFQQBS7Zxa0b2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gowtham1997/indicTrans-1/blob/main/indicTrans_Finetuning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rE4MO-8bDtwD",
        "outputId": "f0ef05d7-cbce-4684-9a9a-c76046718e3e"
      },
      "source": [
        "# create a seperate folder to store everything\n",
        "!mkdir finetuning\n",
        "%cd finetuning"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/finetuning\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-2Rs6_WkD_gF",
        "outputId": "e41d30cc-2f19-43f0-ac46-5cadfbbaa7d2"
      },
      "source": [
        "# clone the repo for running finetuning\n",
        "!git clone https://github.com/AI4Bharat/indicTrans.git\n",
        "%cd indicTrans\n",
        "# clone requirements repositories\n",
        "!git clone https://github.com/anoopkunchukuttan/indic_nlp_library.git\n",
        "!git clone https://github.com/anoopkunchukuttan/indic_nlp_resources.git\n",
        "!git clone https://github.com/rsennrich/subword-nmt.git\n",
        "%cd .."
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'indicTrans'...\n",
            "remote: Enumerating objects: 377, done.\u001b[K\n",
            "remote: Counting objects: 100% (377/377), done.\u001b[K\n",
            "remote: Compressing objects: 100% (247/247), done.\u001b[K\n",
            "remote: Total 377 (delta 219), reused 253 (delta 126), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (377/377), 1.39 MiB | 6.97 MiB/s, done.\n",
            "Resolving deltas: 100% (219/219), done.\n",
            "/content/finetuning/indicTrans\n",
            "Cloning into 'indic_nlp_library'...\n",
            "remote: Enumerating objects: 1271, done.\u001b[K\n",
            "remote: Counting objects: 100% (93/93), done.\u001b[K\n",
            "remote: Compressing objects: 100% (68/68), done.\u001b[K\n",
            "remote: Total 1271 (delta 50), reused 54 (delta 25), pack-reused 1178\u001b[K\n",
            "Receiving objects: 100% (1271/1271), 9.56 MiB | 11.69 MiB/s, done.\n",
            "Resolving deltas: 100% (654/654), done.\n",
            "Cloning into 'indic_nlp_resources'...\n",
            "remote: Enumerating objects: 133, done.\u001b[K\n",
            "remote: Counting objects: 100% (7/7), done.\u001b[K\n",
            "remote: Compressing objects: 100% (7/7), done.\u001b[K\n",
            "remote: Total 133 (delta 0), reused 2 (delta 0), pack-reused 126\u001b[K\n",
            "Receiving objects: 100% (133/133), 149.77 MiB | 23.14 MiB/s, done.\n",
            "Resolving deltas: 100% (51/51), done.\n",
            "Checking out files: 100% (28/28), done.\n",
            "Cloning into 'subword-nmt'...\n",
            "remote: Enumerating objects: 580, done.\u001b[K\n",
            "remote: Counting objects: 100% (4/4), done.\u001b[K\n",
            "remote: Compressing objects: 100% (4/4), done.\u001b[K\n",
            "remote: Total 580 (delta 0), reused 0 (delta 0), pack-reused 576\u001b[K\n",
            "Receiving objects: 100% (580/580), 237.41 KiB | 1.65 MiB/s, done.\n",
            "Resolving deltas: 100% (349/349), done.\n",
            "/content/finetuning\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "duwTvJ9xEBJ1",
        "outputId": "7a0b2166-992d-4401-9cba-cc85a658678a"
      },
      "source": [
        "! sudo apt install tree\n",
        "\n",
        "# Install the necessary libraries\n",
        "!pip install sacremoses pandas mock sacrebleu tensorboardX pyarrow indic-nlp-library\n",
        "# Install fairseq from source\n",
        "!git clone https://github.com/pytorch/fairseq.git\n",
        "%cd fairseq\n",
        "# !git checkout da9eaba12d82b9bfc1442f0e2c6fc1b895f4d35d\n",
        "!pip install --editable ./\n",
        "%cd .."
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/75/ee/67241dc87f266093c533a2d4d3d69438e57d7a90abb216fa076e7d475d4a/sacremoses-0.0.45-py3-none-any.whl (895kB)\n",
            "\u001b[K     |████████████████████████████████| 901kB 5.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (1.1.5)\n",
            "Collecting mock\n",
            "  Downloading https://files.pythonhosted.org/packages/5c/03/b7e605db4a57c0f6fba744b11ef3ddf4ddebcada35022927a2b5fc623fdf/mock-4.0.3-py3-none-any.whl\n",
            "Collecting sacrebleu\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7e/57/0c7ca4e31a126189dab99c19951910bd081dea5bbd25f24b77107750eae7/sacrebleu-1.5.1-py3-none-any.whl (54kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 6.0MB/s \n",
            "\u001b[?25hCollecting tensorboardX\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/07/84/46421bd3e0e89a92682b1a38b40efc22dafb6d8e3d947e4ceefd4a5fabc7/tensorboardX-2.2-py2.py3-none-any.whl (120kB)\n",
            "\u001b[K     |████████████████████████████████| 122kB 40.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyarrow in /usr/local/lib/python3.7/dist-packages (3.0.0)\n",
            "Collecting indic-nlp-library\n",
            "  Downloading https://files.pythonhosted.org/packages/2f/51/f4e4542a226055b73a621ad442c16ae2c913d6b497283c99cae7a9661e6c/indic_nlp_library-0.71-py3-none-any.whl\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from sacremoses) (4.41.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses) (1.0.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses) (7.1.2)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from sacremoses) (2019.12.20)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (2.8.1)\n",
            "Requirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.7/dist-packages (from pandas) (1.19.5)\n",
            "Collecting portalocker==2.0.0\n",
            "  Downloading https://files.pythonhosted.org/packages/89/a6/3814b7107e0788040870e8825eebf214d72166adf656ba7d4bf14759a06a/portalocker-2.0.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.7/dist-packages (from tensorboardX) (3.12.4)\n",
            "Collecting morfessor\n",
            "  Downloading https://files.pythonhosted.org/packages/39/e6/7afea30be2ee4d29ce9de0fa53acbb033163615f849515c0b1956ad074ee/Morfessor-2.0.6-py3-none-any.whl\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.8.0->tensorboardX) (56.1.0)\n",
            "Installing collected packages: sacremoses, mock, portalocker, sacrebleu, tensorboardX, morfessor, indic-nlp-library\n",
            "Successfully installed indic-nlp-library-0.71 mock-4.0.3 morfessor-2.0.6 portalocker-2.0.0 sacrebleu-1.5.1 sacremoses-0.0.45 tensorboardX-2.2\n",
            "Cloning into 'fairseq'...\n",
            "remote: Enumerating objects: 27791, done.\u001b[K\n",
            "remote: Counting objects: 100% (212/212), done.\u001b[K\n",
            "remote: Compressing objects: 100% (121/121), done.\u001b[K\n",
            "remote: Total 27791 (delta 110), reused 145 (delta 90), pack-reused 27579\u001b[K\n",
            "Receiving objects: 100% (27791/27791), 11.61 MiB | 21.90 MiB/s, done.\n",
            "Resolving deltas: 100% (20925/20925), done.\n",
            "/content/finetuning/fairseq\n",
            "Obtaining file:///content/finetuning/fairseq\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: cython in /usr/local/lib/python3.7/dist-packages (from fairseq==1.0.0a0+14439b1) (0.29.22)\n",
            "Collecting hydra-core<1.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/52/e3/fbd70dd0d3ce4d1d75c22d56c0c9f895cfa7ed6587a9ffb821d6812d6a60/hydra_core-1.0.6-py3-none-any.whl (123kB)\n",
            "\u001b[K     |████████████████████████████████| 133kB 4.3MB/s \n",
            "\u001b[?25hCollecting omegaconf<2.1\n",
            "  Downloading https://files.pythonhosted.org/packages/d0/eb/9d63ce09dd8aa85767c65668d5414958ea29648a0eec80a4a7d311ec2684/omegaconf-2.0.6-py3-none-any.whl\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from fairseq==1.0.0a0+14439b1) (2019.12.20)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from fairseq==1.0.0a0+14439b1) (4.41.1)\n",
            "Requirement already satisfied: cffi in /usr/local/lib/python3.7/dist-packages (from fairseq==1.0.0a0+14439b1) (1.14.5)\n",
            "Requirement already satisfied: sacrebleu>=1.4.12 in /usr/local/lib/python3.7/dist-packages (from fairseq==1.0.0a0+14439b1) (1.5.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from fairseq==1.0.0a0+14439b1) (1.8.1+cu101)\n",
            "Requirement already satisfied: numpy; python_version >= \"3.7\" in /usr/local/lib/python3.7/dist-packages (from fairseq==1.0.0a0+14439b1) (1.19.5)\n",
            "Requirement already satisfied: importlib-resources; python_version < \"3.9\" in /usr/local/lib/python3.7/dist-packages (from hydra-core<1.1->fairseq==1.0.0a0+14439b1) (5.1.2)\n",
            "Collecting antlr4-python3-runtime==4.8\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/56/02/789a0bddf9c9b31b14c3e79ec22b9656185a803dc31c15f006f9855ece0d/antlr4-python3-runtime-4.8.tar.gz (112kB)\n",
            "\u001b[K     |████████████████████████████████| 112kB 19.7MB/s \n",
            "\u001b[?25hCollecting PyYAML>=5.1.*\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7a/a5/393c087efdc78091afa2af9f1378762f9821c9c1d7a22c5753fb5ac5f97a/PyYAML-5.4.1-cp37-cp37m-manylinux1_x86_64.whl (636kB)\n",
            "\u001b[K     |████████████████████████████████| 645kB 34.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from omegaconf<2.1->fairseq==1.0.0a0+14439b1) (3.7.4.3)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi->fairseq==1.0.0a0+14439b1) (2.20)\n",
            "Requirement already satisfied: portalocker==2.0.0 in /usr/local/lib/python3.7/dist-packages (from sacrebleu>=1.4.12->fairseq==1.0.0a0+14439b1) (2.0.0)\n",
            "Requirement already satisfied: zipp>=0.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-resources; python_version < \"3.9\"->hydra-core<1.1->fairseq==1.0.0a0+14439b1) (3.4.1)\n",
            "Building wheels for collected packages: antlr4-python3-runtime\n",
            "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.8-cp37-none-any.whl size=141231 sha256=11052d5ddd61c2ac508054d91efb438131c481cc3508382b30d9b2f92ea67d8b\n",
            "  Stored in directory: /root/.cache/pip/wheels/e3/e2/fa/b78480b448b8579ddf393bebd3f47ee23aa84c89b6a78285c8\n",
            "Successfully built antlr4-python3-runtime\n",
            "Installing collected packages: antlr4-python3-runtime, PyYAML, omegaconf, hydra-core, fairseq\n",
            "  Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "  Running setup.py develop for fairseq\n",
            "Successfully installed PyYAML-5.4.1 antlr4-python3-runtime-4.8 fairseq hydra-core-1.0.6 omegaconf-2.0.6\n",
            "/content/finetuning\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oD2EHQdqEH70",
        "outputId": "d7d219da-3320-4743-a985-82a5706d165b"
      },
      "source": [
        "# download the indictrans model\n",
        "\n",
        "\n",
        "# downloading the en-indic model\n",
        "# this will contain:\n",
        "# en-indic/\n",
        "# ├── final_bin                          # contains fairseq dictionaries (we will use this to binarize the new finetuning data)\n",
        "# │   ├── dict.SRC.txt\n",
        "# │   └── dict.TGT.txt\n",
        "# ├── model                              # contains model checkpoint(s)\n",
        "# │   └── checkpoint_best.pt\n",
        "# └── vocab                              # contains bpes for src and tgt (since we train seperate vocabularies) generated with subword_nmt (we will use this bpes to convert finetuning data to subwords)\n",
        "#     ├── bpe_codes.32k.SRC\n",
        "#     ├── bpe_codes.32k.TGT\n",
        "#     ├── vocab.SRC\n",
        "#     └── vocab.TGT\n",
        "\n",
        "\n",
        "\n",
        "!wget https://akpublicdata.blob.core.windows.net/indicnlp/indictrans/inidctrans-en-indic-v0.2.zip\n",
        "!unzip inidctrans-en-indic-v0.2.zip\n",
        "\n",
        "# if you want to finetune indic-en models, use the link below\n",
        "\n",
        "# !wget https://akpublicdata.blob.core.windows.net/indicnlp/indictrans/indictrans-indic-en-v0.2.zip\n",
        "# !unzip indictrans-indic-en-v0.2.zip\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-05-09 08:09:36--  https://akpublicdata.blob.core.windows.net/indicnlp/indictrans/inidctrans-en-indic-v0.2.zip\n",
            "Resolving akpublicdata.blob.core.windows.net (akpublicdata.blob.core.windows.net)... 52.239.246.4\n",
            "Connecting to akpublicdata.blob.core.windows.net (akpublicdata.blob.core.windows.net)|52.239.246.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4609212103 (4.3G) [application/x-zip-compressed]\n",
            "Saving to: ‘inidctrans-en-indic-v0.2.zip.1’\n",
            "\n",
            "inidctrans-en-indic 100%[===================>]   4.29G  10.1MB/s    in 13m 37s \n",
            "\n",
            "2021-05-09 08:23:14 (5.38 MB/s) - ‘inidctrans-en-indic-v0.2.zip.1’ saved [4609212103/4609212103]\n",
            "\n",
            "Archive:  inidctrans-en-indic-v0.2.zip\n",
            "replace en-indic/vocab/bpe_codes.32k.SRC? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lj7XNBuwE0OV",
        "outputId": "9063a0b7-f7b9-4766-bfa2-0ab1e955dc0f"
      },
      "source": [
        "# In this example, we will finetuning on cvit-pib corpus which is part of the WAT2021 training dataset.\n",
        "\n",
        "# Lets first download the full wat2021 training data (cvit-pib is a part of this big training set)\n",
        "!wget http://lotus.kuee.kyoto-u.ac.jp/WAT/indic-multilingual/indic_wat_2021.tar.gz\n",
        "!tar -xzvf indic_wat_2021.tar.gz\n",
        "# all train sets will now be in wat2021/train\n",
        "!mv finalrepo wat2021"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-05-09 08:23:34--  http://lotus.kuee.kyoto-u.ac.jp/WAT/indic-multilingual/indic_wat_2021.tar.gz\n",
            "Resolving lotus.kuee.kyoto-u.ac.jp (lotus.kuee.kyoto-u.ac.jp)... 130.54.208.131\n",
            "Connecting to lotus.kuee.kyoto-u.ac.jp (lotus.kuee.kyoto-u.ac.jp)|130.54.208.131|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 910154812 (868M) [application/x-gzip]\n",
            "Saving to: ‘indic_wat_2021.tar.gz’\n",
            "\n",
            "indic_wat_2021.tar. 100%[===================>] 867.99M  55.7MB/s    in 16s     \n",
            "\n",
            "2021-05-09 08:23:50 (55.8 MB/s) - ‘indic_wat_2021.tar.gz’ saved [910154812/910154812]\n",
            "\n",
            "finalrepo/\n",
            "finalrepo/README\n",
            "finalrepo/dev/\n",
            "finalrepo/dev/dev.mr\n",
            "finalrepo/dev/dev.kn\n",
            "finalrepo/dev/dev.gu\n",
            "finalrepo/dev/dev.ta\n",
            "finalrepo/dev/dev.bn\n",
            "finalrepo/dev/dev.pa\n",
            "finalrepo/dev/dev.ml\n",
            "finalrepo/dev/dev.or\n",
            "finalrepo/dev/dev.en\n",
            "finalrepo/dev/dev.hi\n",
            "finalrepo/dev/dev.te\n",
            "finalrepo/train/\n",
            "finalrepo/train/opensubtitles/\n",
            "finalrepo/train/opensubtitles/en-ta/\n",
            "finalrepo/train/opensubtitles/en-ta/train.ta\n",
            "finalrepo/train/opensubtitles/en-ta/train.en\n",
            "finalrepo/train/opensubtitles/en-te/\n",
            "finalrepo/train/opensubtitles/en-te/train.te\n",
            "finalrepo/train/opensubtitles/en-te/train.en\n",
            "finalrepo/train/opensubtitles/en-ml/\n",
            "finalrepo/train/opensubtitles/en-ml/train.ml\n",
            "finalrepo/train/opensubtitles/en-ml/train.en\n",
            "finalrepo/train/opensubtitles/en-bn/\n",
            "finalrepo/train/opensubtitles/en-bn/train.bn\n",
            "finalrepo/train/opensubtitles/en-bn/train.en\n",
            "finalrepo/train/opensubtitles/en-hi/\n",
            "finalrepo/train/opensubtitles/en-hi/train.hi\n",
            "finalrepo/train/opensubtitles/en-hi/train.en\n",
            "finalrepo/train/cvit-pib/\n",
            "finalrepo/train/cvit-pib/en-ta/\n",
            "finalrepo/train/cvit-pib/en-ta/train.ta\n",
            "finalrepo/train/cvit-pib/en-ta/train.en\n",
            "finalrepo/train/cvit-pib/en-te/\n",
            "finalrepo/train/cvit-pib/en-te/train.te\n",
            "finalrepo/train/cvit-pib/en-te/train.en\n",
            "finalrepo/train/cvit-pib/en-or/\n",
            "finalrepo/train/cvit-pib/en-or/train.or\n",
            "finalrepo/train/cvit-pib/en-or/train.en\n",
            "finalrepo/train/cvit-pib/en-ml/\n",
            "finalrepo/train/cvit-pib/en-ml/train.ml\n",
            "finalrepo/train/cvit-pib/en-ml/train.en\n",
            "finalrepo/train/cvit-pib/en-bn/\n",
            "finalrepo/train/cvit-pib/en-bn/train.bn\n",
            "finalrepo/train/cvit-pib/en-bn/train.en\n",
            "finalrepo/train/cvit-pib/en-gu/\n",
            "finalrepo/train/cvit-pib/en-gu/train.en\n",
            "finalrepo/train/cvit-pib/en-gu/train.gu\n",
            "finalrepo/train/cvit-pib/en-mr/\n",
            "finalrepo/train/cvit-pib/en-mr/train.mr\n",
            "finalrepo/train/cvit-pib/en-mr/train.en\n",
            "finalrepo/train/cvit-pib/en-pa/\n",
            "finalrepo/train/cvit-pib/en-pa/train.pa\n",
            "finalrepo/train/cvit-pib/en-pa/train.en\n",
            "finalrepo/train/cvit-pib/en-hi/\n",
            "finalrepo/train/cvit-pib/en-hi/train.hi\n",
            "finalrepo/train/cvit-pib/en-hi/train.en\n",
            "finalrepo/train/bibleuedin/\n",
            "finalrepo/train/bibleuedin/en-te/\n",
            "finalrepo/train/bibleuedin/en-te/train.te\n",
            "finalrepo/train/bibleuedin/en-te/train.en\n",
            "finalrepo/train/bibleuedin/en-ml/\n",
            "finalrepo/train/bibleuedin/en-ml/train.ml\n",
            "finalrepo/train/bibleuedin/en-ml/train.en\n",
            "finalrepo/train/bibleuedin/en-gu/\n",
            "finalrepo/train/bibleuedin/en-gu/train.en\n",
            "finalrepo/train/bibleuedin/en-gu/train.gu\n",
            "finalrepo/train/bibleuedin/en-mr/\n",
            "finalrepo/train/bibleuedin/en-mr/train.mr\n",
            "finalrepo/train/bibleuedin/en-mr/train.en\n",
            "finalrepo/train/bibleuedin/en-hi/\n",
            "finalrepo/train/bibleuedin/en-hi/train.hi\n",
            "finalrepo/train/bibleuedin/en-hi/train.en\n",
            "finalrepo/train/bibleuedin/en-kn/\n",
            "finalrepo/train/bibleuedin/en-kn/train.kn\n",
            "finalrepo/train/bibleuedin/en-kn/train.en\n",
            "finalrepo/train/iitb/\n",
            "finalrepo/train/iitb/en-hi/\n",
            "finalrepo/train/iitb/en-hi/train.hi\n",
            "finalrepo/train/iitb/en-hi/train.en\n",
            "finalrepo/train/wikimatrix/\n",
            "finalrepo/train/wikimatrix/en-ta/\n",
            "finalrepo/train/wikimatrix/en-ta/train.ta\n",
            "finalrepo/train/wikimatrix/en-ta/train.en\n",
            "finalrepo/train/wikimatrix/en-te/\n",
            "finalrepo/train/wikimatrix/en-te/train.te\n",
            "finalrepo/train/wikimatrix/en-te/train.en\n",
            "finalrepo/train/wikimatrix/en-ml/\n",
            "finalrepo/train/wikimatrix/en-ml/train.ml\n",
            "finalrepo/train/wikimatrix/en-ml/train.en\n",
            "finalrepo/train/wikimatrix/en-bn/\n",
            "finalrepo/train/wikimatrix/en-bn/train.bn\n",
            "finalrepo/train/wikimatrix/en-bn/train.en\n",
            "finalrepo/train/wikimatrix/en-mr/\n",
            "finalrepo/train/wikimatrix/en-mr/train.mr\n",
            "finalrepo/train/wikimatrix/en-mr/train.en\n",
            "finalrepo/train/wikimatrix/en-hi/\n",
            "finalrepo/train/wikimatrix/en-hi/train.hi\n",
            "finalrepo/train/wikimatrix/en-hi/train.en\n",
            "finalrepo/train/alt/\n",
            "finalrepo/train/alt/en-bn/\n",
            "finalrepo/train/alt/en-bn/train.bn\n",
            "finalrepo/train/alt/en-bn/train.en\n",
            "finalrepo/train/alt/en-hi/\n",
            "finalrepo/train/alt/en-hi/train.hi\n",
            "finalrepo/train/alt/en-hi/train.en\n",
            "finalrepo/train/pmi/\n",
            "finalrepo/train/pmi/en-ta/\n",
            "finalrepo/train/pmi/en-ta/train.ta\n",
            "finalrepo/train/pmi/en-ta/train.en\n",
            "finalrepo/train/pmi/en-te/\n",
            "finalrepo/train/pmi/en-te/train.te\n",
            "finalrepo/train/pmi/en-te/train.en\n",
            "finalrepo/train/pmi/en-or/\n",
            "finalrepo/train/pmi/en-or/train.or\n",
            "finalrepo/train/pmi/en-or/train.en\n",
            "finalrepo/train/pmi/en-ml/\n",
            "finalrepo/train/pmi/en-ml/train.ml\n",
            "finalrepo/train/pmi/en-ml/train.en\n",
            "finalrepo/train/pmi/en-bn/\n",
            "finalrepo/train/pmi/en-bn/train.bn\n",
            "finalrepo/train/pmi/en-bn/train.en\n",
            "finalrepo/train/pmi/en-gu/\n",
            "finalrepo/train/pmi/en-gu/train.en\n",
            "finalrepo/train/pmi/en-gu/train.gu\n",
            "finalrepo/train/pmi/en-mr/\n",
            "finalrepo/train/pmi/en-mr/train.mr\n",
            "finalrepo/train/pmi/en-mr/train.en\n",
            "finalrepo/train/pmi/en-pa/\n",
            "finalrepo/train/pmi/en-pa/train.pa\n",
            "finalrepo/train/pmi/en-pa/train.en\n",
            "finalrepo/train/pmi/en-hi/\n",
            "finalrepo/train/pmi/en-hi/train.hi\n",
            "finalrepo/train/pmi/en-hi/train.en\n",
            "finalrepo/train/pmi/en-kn/\n",
            "finalrepo/train/pmi/en-kn/train.kn\n",
            "finalrepo/train/pmi/en-kn/train.en\n",
            "finalrepo/train/wikititles/\n",
            "finalrepo/train/wikititles/en-ta/\n",
            "finalrepo/train/wikititles/en-ta/train.ta\n",
            "finalrepo/train/wikititles/en-ta/train.en\n",
            "finalrepo/train/wikititles/en-gu/\n",
            "finalrepo/train/wikititles/en-gu/train.en\n",
            "finalrepo/train/wikititles/en-gu/train.gu\n",
            "finalrepo/train/mtenglish2odia/\n",
            "finalrepo/train/mtenglish2odia/en-or/\n",
            "finalrepo/train/mtenglish2odia/en-or/train.or\n",
            "finalrepo/train/mtenglish2odia/en-or/train.en\n",
            "finalrepo/train/urst/\n",
            "finalrepo/train/urst/en-gu/\n",
            "finalrepo/train/urst/en-gu/train.en\n",
            "finalrepo/train/urst/en-gu/train.gu\n",
            "finalrepo/train/jw/\n",
            "finalrepo/train/jw/en-ta/\n",
            "finalrepo/train/jw/en-ta/train.ta\n",
            "finalrepo/train/jw/en-ta/train.en\n",
            "finalrepo/train/jw/en-te/\n",
            "finalrepo/train/jw/en-te/train.te\n",
            "finalrepo/train/jw/en-te/train.en\n",
            "finalrepo/train/jw/en-ml/\n",
            "finalrepo/train/jw/en-ml/train.ml\n",
            "finalrepo/train/jw/en-ml/train.en\n",
            "finalrepo/train/jw/en-bn/\n",
            "finalrepo/train/jw/en-bn/train.bn\n",
            "finalrepo/train/jw/en-bn/train.en\n",
            "finalrepo/train/jw/en-gu/\n",
            "finalrepo/train/jw/en-gu/train.en\n",
            "finalrepo/train/jw/en-gu/train.gu\n",
            "finalrepo/train/jw/en-mr/\n",
            "finalrepo/train/jw/en-mr/train.mr\n",
            "finalrepo/train/jw/en-mr/train.en\n",
            "finalrepo/train/jw/en-pa/\n",
            "finalrepo/train/jw/en-pa/train.pa\n",
            "finalrepo/train/jw/en-pa/train.en\n",
            "finalrepo/train/jw/en-hi/\n",
            "finalrepo/train/jw/en-hi/train.hi\n",
            "finalrepo/train/jw/en-hi/train.en\n",
            "finalrepo/train/jw/en-kn/\n",
            "finalrepo/train/jw/en-kn/train.kn\n",
            "finalrepo/train/jw/en-kn/train.en\n",
            "finalrepo/train/nlpc/\n",
            "finalrepo/train/nlpc/en-ta/\n",
            "finalrepo/train/nlpc/en-ta/train.ta\n",
            "finalrepo/train/nlpc/en-ta/train.en\n",
            "finalrepo/train/ufal/\n",
            "finalrepo/train/ufal/en-ta/\n",
            "finalrepo/train/ufal/en-ta/train.ta\n",
            "finalrepo/train/ufal/en-ta/train.en\n",
            "finalrepo/train/odiencorp/\n",
            "finalrepo/train/odiencorp/en-or/\n",
            "finalrepo/train/odiencorp/en-or/train.or\n",
            "finalrepo/train/odiencorp/en-or/train.en\n",
            "finalrepo/train/tanzil/\n",
            "finalrepo/train/tanzil/en-ta/\n",
            "finalrepo/train/tanzil/en-ta/train.ta\n",
            "finalrepo/train/tanzil/en-ta/train.en\n",
            "finalrepo/train/tanzil/en-ml/\n",
            "finalrepo/train/tanzil/en-ml/train.ml\n",
            "finalrepo/train/tanzil/en-ml/train.en\n",
            "finalrepo/train/tanzil/en-bn/\n",
            "finalrepo/train/tanzil/en-bn/train.bn\n",
            "finalrepo/train/tanzil/en-bn/train.en\n",
            "finalrepo/train/tanzil/en-hi/\n",
            "finalrepo/train/tanzil/en-hi/train.hi\n",
            "finalrepo/train/tanzil/en-hi/train.en\n",
            "finalrepo/train/ted2020/\n",
            "finalrepo/train/ted2020/en-ta/\n",
            "finalrepo/train/ted2020/en-ta/train.ta\n",
            "finalrepo/train/ted2020/en-ta/train.en\n",
            "finalrepo/train/ted2020/en-te/\n",
            "finalrepo/train/ted2020/en-te/train.te\n",
            "finalrepo/train/ted2020/en-te/train.en\n",
            "finalrepo/train/ted2020/en-ml/\n",
            "finalrepo/train/ted2020/en-ml/train.ml\n",
            "finalrepo/train/ted2020/en-ml/train.en\n",
            "finalrepo/train/ted2020/en-bn/\n",
            "finalrepo/train/ted2020/en-bn/train.bn\n",
            "finalrepo/train/ted2020/en-bn/train.en\n",
            "finalrepo/train/ted2020/en-gu/\n",
            "finalrepo/train/ted2020/en-gu/train.en\n",
            "finalrepo/train/ted2020/en-gu/train.gu\n",
            "finalrepo/train/ted2020/en-mr/\n",
            "finalrepo/train/ted2020/en-mr/train.mr\n",
            "finalrepo/train/ted2020/en-mr/train.en\n",
            "finalrepo/train/ted2020/en-pa/\n",
            "finalrepo/train/ted2020/en-pa/train.pa\n",
            "finalrepo/train/ted2020/en-pa/train.en\n",
            "finalrepo/train/ted2020/en-hi/\n",
            "finalrepo/train/ted2020/en-hi/train.hi\n",
            "finalrepo/train/ted2020/en-hi/train.en\n",
            "finalrepo/train/ted2020/en-kn/\n",
            "finalrepo/train/ted2020/en-kn/train.kn\n",
            "finalrepo/train/ted2020/en-kn/train.en\n",
            "finalrepo/test/\n",
            "finalrepo/test/test.gu\n",
            "finalrepo/test/test.kn\n",
            "finalrepo/test/test.ta\n",
            "finalrepo/test/test.pa\n",
            "finalrepo/test/test.bn\n",
            "finalrepo/test/test.hi\n",
            "finalrepo/test/test.ml\n",
            "finalrepo/test/test.or\n",
            "finalrepo/test/test.mr\n",
            "finalrepo/test/test.en\n",
            "finalrepo/test/test.te\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ys_QURP3Sx7G"
      },
      "source": [
        "# wat2021\n",
        "# ├── dev                    # contains Wat2021 dev data\n",
        "# │   ├── dev.bn\n",
        "# │   ├── dev.en\n",
        "# │   ├── dev.gu\n",
        "# │   ├── dev.hi\n",
        "# │   ├── dev.kn\n",
        "# │   ├── dev.ml\n",
        "# │   ├── dev.mr\n",
        "# │   ├── dev.or\n",
        "# │   ├── dev.pa\n",
        "# │   ├── dev.ta\n",
        "# │   └── dev.te\n",
        "# ├── README\n",
        "# ├── test                  # contains Wat2021 test data\n",
        "# │   ├── test.bn\n",
        "# │   ├── test.en\n",
        "# │   ├── test.gu\n",
        "# │   ├── test.hi\n",
        "# │   ├── test.kn\n",
        "# │   ├── test.ml\n",
        "# │   ├── test.mr\n",
        "# │   ├── test.or\n",
        "# │   ├── test.pa\n",
        "# │   ├── test.ta\n",
        "# │   └── test.te\n",
        "# └── train                 # contains WAT2021 train data which has lot of corpuses (alt, bible, Jw300, etc)\n",
        "#     ├── alt/\n",
        "#     ├── bibleuedin/\n",
        "#     ├── iitb/\n",
        "#     ├── jw/\n",
        "#     ├── mtenglish2odia/\n",
        "#     ├── nlpc/\n",
        "#     ├── odiencorp/\n",
        "#     ├── opensubtitles/\n",
        "#     ├── pmi/\n",
        "#     ├── tanzil/\n",
        "#     ├── ted2020/\n",
        "#     ├── ufal/\n",
        "#     ├── urst/\n",
        "#     ├── wikimatrix/\n",
        "#     ├── wikititles/\n",
        "#     └──  cvit-pib         \n",
        "#         ├── en-bn         # within a train corpus folder the files are arranged in {src_lang}-{tgt_lang}/train.{src_lang}, train.{tgt_lang}\n",
        "#         │   ├── train.bn\n",
        "#         │   └── train.en\n",
        "#         ├── en-gu\n",
        "#         │   ├── train.en\n",
        "#         │   └── train.gu\n",
        "#         ├── en-hi\n",
        "#         │   ├── train.en\n",
        "#         │   └── train.hi\n",
        "#         ├── en-ml\n",
        "#         │   ├── train.en\n",
        "#         │   └── train.ml\n",
        "#         ├── en-mr\n",
        "#         │   ├── train.en\n",
        "#         │   └── train.mr\n",
        "#         ├── en-or\n",
        "#         │   ├── train.en\n",
        "#         │   └── train.or\n",
        "#         ├── en-pa\n",
        "#         │   ├── train.en\n",
        "#         │   └── train.pa\n",
        "#         ├── en-ta\n",
        "#         │   ├── train.en\n",
        "#         │   └── train.ta\n",
        "#         └── en-te\n",
        "#             ├── train.en\n",
        "#             └── train.te\n",
        "\n",
        "\n",
        "\n",
        "# instead of using all the data for this example, we will mainly use the cvit-pib corpus from wat2021 train set\n",
        "# for dev and test set, we will use the dev and test provided by wat2021\n",
        "\n",
        "# In case, you want to finetune on all these corpuses, you would need to merge all the training data into one folder and remove duplicate train sentence pairs.\n",
        "# To do this, refer to this gist: https://gist.github.com/gowtham1997/2524f8e9559cff586d1f935e621fc598\n",
        "\n",
        "\n",
        "# copy everything to a dataset folder\n",
        "!mkdir -p dataset/train\n",
        "! cp -r wat2021/train/cvit-pib/* dataset/train\n",
        "! cp -r wat2021/dev dataset\n",
        "! cp -r wat2021/test dataset\n",
        "\n",
        "\n",
        "# lets cd to indicTrans\n",
        " %cd indicTrans"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8yPTbM_clKfI",
        "outputId": "6c3e9598-40c3-4893-dd55-69304fc5f741"
      },
      "source": [
        "%%shell\n",
        "\n",
        "exp_dir=../dataset\n",
        "src_lang=en\n",
        "tgt_lang=indic\n",
        "\n",
        "# change this to indic-en, if you have downloaded the indic-en dir\n",
        "download_dir=../en-indic\n",
        "\n",
        "train_data_dir=$exp_dir/train\n",
        "dev_data_dir=$exp_dir/dev\n",
        "test_data_dir=$exp_dir/test\n",
        "echo $exp_dir\n",
        "\n"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "../dataset\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              ""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NhwUXyYVXrOY",
        "outputId": "5fb19ad0-913f-4139-a4bd-e7f3e8b66d53"
      },
      "source": [
        "# all the data preparation happens in this cell\n",
        "%%shell\n",
        "\n",
        "exp_dir=../dataset\n",
        "src_lang=en\n",
        "tgt_lang=indic\n",
        "\n",
        "# change this to indic-en, if you have downloaded the indic-en dir\n",
        "download_dir=../en-indic\n",
        "\n",
        "train_data_dir=$exp_dir/train\n",
        "dev_data_dir=$exp_dir/dev\n",
        "test_data_dir=$exp_dir/test\n",
        "\n",
        "\n",
        "echo \"Running experiment ${exp_dir} on ${src_lang} to ${tgt_lang}\"\n",
        "\n",
        "\n",
        "train_processed_dir=$exp_dir/data\n",
        "devtest_processed_dir=$exp_dir/data\n",
        "\n",
        "out_data_dir=$exp_dir/final_bin\n",
        "\n",
        "mkdir -p $train_processed_dir\n",
        "mkdir -p $devtest_processed_dir\n",
        "mkdir -p $out_data_dir\n",
        "\n",
        "# indic languages.\n",
        "# cvit-pib corpus does not have as (assamese) and kn (kannada), hence its not part of this list\n",
        "langs=(bn hi gu ml mr or pa ta te)\n",
        "\n",
        "# for lang in ${langs[@]};do\n",
        "# \tif [ $src_lang == en ]; then\n",
        "# \t\ttgt_lang=$lang\n",
        "# \telse\n",
        "# \t\tsrc_lang=$lang\n",
        "# \tfi\n",
        "\n",
        "# \ttrain_norm_dir=$exp_dir/norm/$src_lang-$tgt_lang\n",
        "# \tdevtest_norm_dir=$exp_dir/norm/$src_lang-$tgt_lang\n",
        "# \tmkdir -p $train_norm_dir\n",
        "# \tmkdir -p $devtest_norm_dir\n",
        "\n",
        "\n",
        "#     # preprocessing pretokenizes the input (we use moses tokenizer for en and indicnlp lib for indic languages)\n",
        "#     # after pretokenization, we use indicnlp to transliterate all the indic data to devnagiri script\n",
        "\n",
        "# \t# train preprocessing\n",
        "# \ttrain_infname_src=$train_data_dir/en-${lang}/train.$src_lang\n",
        "# \ttrain_infname_tgt=$train_data_dir/en-${lang}/train.$tgt_lang\n",
        "# \ttrain_outfname_src=$train_norm_dir/train.$src_lang\n",
        "# \ttrain_outfname_tgt=$train_norm_dir/train.$tgt_lang\n",
        "# \techo \"Applying normalization and script conversion for train $lang\"\n",
        "# \tinput_size=`python scripts/preprocess_translate.py $train_infname_src $train_outfname_src $src_lang true`\n",
        "# \tinput_size=`python scripts/preprocess_translate.py $train_infname_tgt $train_outfname_tgt $tgt_lang true`\n",
        "# \techo \"Number of sentences in train $lang: $input_size\"\n",
        "\n",
        "# \t# dev preprocessing\n",
        "# \tdev_infname_src=$dev_data_dir/dev.$src_lang\n",
        "# \tdev_infname_tgt=$dev_data_dir/dev.$tgt_lang\n",
        "# \tdev_outfname_src=$devtest_norm_dir/dev.$src_lang\n",
        "# \tdev_outfname_tgt=$devtest_norm_dir/dev.$tgt_lang\n",
        "# \techo \"Applying normalization and script conversion for dev $lang\"\n",
        "# \tinput_size=`python scripts/preprocess_translate.py $dev_infname_src $dev_outfname_src $src_lang true`\n",
        "# \tinput_size=`python scripts/preprocess_translate.py $dev_infname_tgt $dev_outfname_tgt $tgt_lang true`\n",
        "# \techo \"Number of sentences in dev $lang: $input_size\"\n",
        "\n",
        "# \t# test preprocessing\n",
        "# \ttest_infname_src=$test_data_dir/test.$src_lang\n",
        "# \ttest_infname_tgt=$test_data_dir/test.$tgt_lang\n",
        "# \ttest_outfname_src=$devtest_norm_dir/test.$src_lang\n",
        "# \ttest_outfname_tgt=$devtest_norm_dir/test.$tgt_lang\n",
        "# \techo \"Applying normalization and script conversion for test $lang\"\n",
        "# \tinput_size=`python scripts/preprocess_translate.py $test_infname_src $test_outfname_src $src_lang true`\n",
        "# \tinput_size=`python scripts/preprocess_translate.py $test_infname_tgt $test_outfname_tgt $tgt_lang true`\n",
        "# \techo \"Number of sentences in test $lang: $input_size\"\n",
        "# done\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Now that we have preprocessed all the data, we can now merge these different text files into one\n",
        "# ie. for en-as, we have train.en and corresponding train.as, similarly for en-bn, we have train.en and corresponding train.bn\n",
        "# now we will concatenate all this into en-X where train.SRC will have all the en (src) training data and train.TGT will have all the concatenated indic lang data\n",
        "\n",
        "python scripts/concat_joint_data.py $exp_dir/norm $exp_dir/data $src_lang $tgt_lang 'train'\n",
        "python scripts/concat_joint_data.py $exp_dir/norm $exp_dir/data $src_lang $tgt_lang 'dev'\n",
        "python scripts/concat_joint_data.py $exp_dir/norm $exp_dir/data $src_lang $tgt_lang 'test'\n",
        "\n",
        "# use the vocab from downloaded dir\n",
        "cp -r $download_dir/vocab $exp_dir\n",
        "\n",
        "\n",
        "echo \"Applying bpe to the new finetuning data\"\n",
        "bash apply_single_bpe_traindevtest_notag.sh $exp_dir\n",
        "\n",
        "mkdir -p $exp_dir/final\n",
        "\n",
        "# We also add special tags to indicate the source and target language in the inputs\n",
        "#  Eg: to translate a sentence from english to hindi , the input would be   __src__en__   __tgt__hi__ <en bpe tokens>\n",
        "\n",
        "echo \"Adding language tags\"\n",
        "python scripts/add_joint_tags_translate.py $exp_dir 'train'\n",
        "python scripts/add_joint_tags_translate.py $exp_dir 'dev'\n",
        "python scripts/add_joint_tags_translate.py $exp_dir 'test'\n",
        "\n",
        "\n",
        "\n",
        "data_dir=$exp_dir/final\n",
        "out_data_dir=$exp_dir/final_bin\n",
        "\n",
        "rm -rf $out_data_dir\n",
        "\n",
        "# binarizing the new data (train, dev and test) using dictionary from the download dir\n",
        "\n",
        " num_workers=`python -c \"import multiprocessing; print(multiprocessing.cpu_count())\"`\n",
        "\n",
        "data_dir=$exp_dir/final\n",
        "out_data_dir=$exp_dir/final_bin\n",
        "\n",
        "# rm -rf $out_data_dir\n",
        "\n",
        "echo \"Binarizing data. This will take some time depending on the size of finetuning data\"\n",
        "fairseq-preprocess --source-lang SRC --target-lang TGT \\\n",
        " --trainpref $data_dir/train --validpref $data_dir/dev --testpref $data_dir/test \\\n",
        " --destdir $out_data_dir --workers $num_workers \\\n",
        " --srcdict $download_dir/final_bin/dict.SRC.txt --tgtdict $download_dir/final_bin/dict.TGT.txt --thresholdtgt 5 --thresholdsrc 5  "
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Running experiment ../dataset on en to indic\n",
            "\n",
            "../dataset/data/train.SRC\n",
            "../dataset/data/train.TGT\n",
            "\r  0% 0/11 [00:00<?, ?it/s]src: en, tgt:as\n",
            "src: en, tgt:bn\n",
            "../dataset/norm/en-bn/train.en\n",
            "../dataset/norm/en-bn/train.bn\n",
            " 18% 2/11 [00:00<00:00, 12.74it/s]src: en, tgt:gu\n",
            "../dataset/norm/en-gu/train.en\n",
            "../dataset/norm/en-gu/train.gu\n",
            "src: en, tgt:hi\n",
            "../dataset/norm/en-hi/train.en\n",
            "../dataset/norm/en-hi/train.hi\n",
            " 36% 4/11 [00:00<00:01,  6.18it/s]src: en, tgt:kn\n",
            "src: en, tgt:ml\n",
            "../dataset/norm/en-ml/train.en\n",
            "../dataset/norm/en-ml/train.ml\n",
            " 55% 6/11 [00:01<00:00,  7.42it/s]src: en, tgt:mr\n",
            "../dataset/norm/en-mr/train.en\n",
            "../dataset/norm/en-mr/train.mr\n",
            " 64% 7/11 [00:01<00:00,  5.44it/s]src: en, tgt:or\n",
            "../dataset/norm/en-or/train.en\n",
            "../dataset/norm/en-or/train.or\n",
            " 73% 8/11 [00:01<00:00,  5.31it/s]src: en, tgt:pa\n",
            "../dataset/norm/en-pa/train.en\n",
            "../dataset/norm/en-pa/train.pa\n",
            " 82% 9/11 [00:01<00:00,  4.98it/s]src: en, tgt:ta\n",
            "../dataset/norm/en-ta/train.en\n",
            "../dataset/norm/en-ta/train.ta\n",
            " 91% 10/11 [00:02<00:00,  4.38it/s]src: en, tgt:te\n",
            "../dataset/norm/en-te/train.en\n",
            "../dataset/norm/en-te/train.te\n",
            "100% 11/11 [00:02<00:00,  5.12it/s]\n",
            "  0% 0/11 [00:00<?, ?it/s]src: en, tgt:as\n",
            "src: en, tgt:bn\n",
            "../dataset/norm/en-bn/train.en\n",
            "src: en, tgt:gu\n",
            "../dataset/norm/en-gu/train.en\n",
            "src: en, tgt:hi\n",
            "../dataset/norm/en-hi/train.en\n",
            " 36% 4/11 [00:00<00:00, 27.86it/s]src: en, tgt:kn\n",
            "src: en, tgt:ml\n",
            "../dataset/norm/en-ml/train.en\n",
            "src: en, tgt:mr\n",
            "../dataset/norm/en-mr/train.en\n",
            "src: en, tgt:or\n",
            "../dataset/norm/en-or/train.en\n",
            "src: en, tgt:pa\n",
            "../dataset/norm/en-pa/train.en\n",
            "src: en, tgt:ta\n",
            "../dataset/norm/en-ta/train.en\n",
            " 91% 10/11 [00:00<00:00, 32.18it/s]src: en, tgt:te\n",
            "../dataset/norm/en-te/train.en\n",
            "100% 11/11 [00:00<00:00, 40.03it/s]\n",
            "\n",
            "../dataset/data/dev.SRC\n",
            "../dataset/data/dev.TGT\n",
            "  0% 0/11 [00:00<?, ?it/s]src: en, tgt:as\n",
            "src: en, tgt:bn\n",
            "../dataset/norm/en-bn/dev.en\n",
            "../dataset/norm/en-bn/dev.bn\n",
            "src: en, tgt:gu\n",
            "../dataset/norm/en-gu/dev.en\n",
            "../dataset/norm/en-gu/dev.gu\n",
            "src: en, tgt:hi\n",
            "../dataset/norm/en-hi/dev.en\n",
            "../dataset/norm/en-hi/dev.hi\n",
            "src: en, tgt:kn\n",
            "../dataset/norm/en-kn/dev.en\n",
            "../dataset/norm/en-kn/dev.kn\n",
            "src: en, tgt:ml\n",
            "../dataset/norm/en-ml/dev.en\n",
            "../dataset/norm/en-ml/dev.ml\n",
            "src: en, tgt:mr\n",
            "../dataset/norm/en-mr/dev.en\n",
            "../dataset/norm/en-mr/dev.mr\n",
            "src: en, tgt:or\n",
            "../dataset/norm/en-or/dev.en\n",
            "../dataset/norm/en-or/dev.or\n",
            "src: en, tgt:pa\n",
            "../dataset/norm/en-pa/dev.en\n",
            "../dataset/norm/en-pa/dev.pa\n",
            " 82% 9/11 [00:00<00:00, 81.20it/s]src: en, tgt:ta\n",
            "../dataset/norm/en-ta/dev.en\n",
            "../dataset/norm/en-ta/dev.ta\n",
            "src: en, tgt:te\n",
            "../dataset/norm/en-te/dev.en\n",
            "../dataset/norm/en-te/dev.te\n",
            "100% 11/11 [00:00<00:00, 79.96it/s]\n",
            "  0% 0/11 [00:00<?, ?it/s]src: en, tgt:as\n",
            "../dataset/norm/en-as/dev.en\n",
            "src: en, tgt:bn\n",
            "../dataset/norm/en-bn/dev.en\n",
            "src: en, tgt:gu\n",
            "../dataset/norm/en-gu/dev.en\n",
            "src: en, tgt:hi\n",
            "../dataset/norm/en-hi/dev.en\n",
            "src: en, tgt:kn\n",
            "../dataset/norm/en-kn/dev.en\n",
            "src: en, tgt:ml\n",
            "../dataset/norm/en-ml/dev.en\n",
            "src: en, tgt:mr\n",
            "../dataset/norm/en-mr/dev.en\n",
            "src: en, tgt:or\n",
            "../dataset/norm/en-or/dev.en\n",
            "src: en, tgt:pa\n",
            "../dataset/norm/en-pa/dev.en\n",
            "src: en, tgt:ta\n",
            "../dataset/norm/en-ta/dev.en\n",
            "src: en, tgt:te\n",
            "../dataset/norm/en-te/dev.en\n",
            "100% 11/11 [00:00<00:00, 2956.01it/s]\n",
            "\n",
            "../dataset/data/test.SRC\n",
            "../dataset/data/test.TGT\n",
            "  0% 0/11 [00:00<?, ?it/s]src: en, tgt:as\n",
            "src: en, tgt:bn\n",
            "../dataset/norm/en-bn/test.en\n",
            "../dataset/norm/en-bn/test.bn\n",
            "src: en, tgt:gu\n",
            "../dataset/norm/en-gu/test.en\n",
            "../dataset/norm/en-gu/test.gu\n",
            "src: en, tgt:hi\n",
            "../dataset/norm/en-hi/test.en\n",
            "../dataset/norm/en-hi/test.hi\n",
            "src: en, tgt:kn\n",
            "../dataset/norm/en-kn/test.en\n",
            "../dataset/norm/en-kn/test.kn\n",
            "src: en, tgt:ml\n",
            "../dataset/norm/en-ml/test.en\n",
            "../dataset/norm/en-ml/test.ml\n",
            "src: en, tgt:mr\n",
            "../dataset/norm/en-mr/test.en\n",
            "../dataset/norm/en-mr/test.mr\n",
            "src: en, tgt:or\n",
            "../dataset/norm/en-or/test.en\n",
            "../dataset/norm/en-or/test.or\n",
            " 73% 8/11 [00:00<00:00, 77.36it/s]src: en, tgt:pa\n",
            "../dataset/norm/en-pa/test.en\n",
            "../dataset/norm/en-pa/test.pa\n",
            "src: en, tgt:ta\n",
            "../dataset/norm/en-ta/test.en\n",
            "../dataset/norm/en-ta/test.ta\n",
            "src: en, tgt:te\n",
            "../dataset/norm/en-te/test.en\n",
            "../dataset/norm/en-te/test.te\n",
            "100% 11/11 [00:00<00:00, 74.02it/s]\n",
            "  0% 0/11 [00:00<?, ?it/s]src: en, tgt:as\n",
            "../dataset/norm/en-as/test.en\n",
            "src: en, tgt:bn\n",
            "../dataset/norm/en-bn/test.en\n",
            "src: en, tgt:gu\n",
            "../dataset/norm/en-gu/test.en\n",
            "src: en, tgt:hi\n",
            "../dataset/norm/en-hi/test.en\n",
            "src: en, tgt:kn\n",
            "../dataset/norm/en-kn/test.en\n",
            "src: en, tgt:ml\n",
            "../dataset/norm/en-ml/test.en\n",
            "src: en, tgt:mr\n",
            "../dataset/norm/en-mr/test.en\n",
            "src: en, tgt:or\n",
            "../dataset/norm/en-or/test.en\n",
            "src: en, tgt:pa\n",
            "../dataset/norm/en-pa/test.en\n",
            "src: en, tgt:ta\n",
            "../dataset/norm/en-ta/test.en\n",
            "src: en, tgt:te\n",
            "../dataset/norm/en-te/test.en\n",
            "100% 11/11 [00:00<00:00, 1354.83it/s]\n",
            "Applying bpe to the new finetuning data\n",
            "train\n",
            "Apply to SRC corpus\n",
            "subword-nmt/subword_nmt/apply_bpe.py:444: UserWarning: In parallel mode, the input cannot be STDIN. Using 1 processor instead.\n",
            "  warnings.warn(\"In parallel mode, the input cannot be STDIN. Using 1 processor instead.\")\n",
            "Apply to TGT corpus\n",
            "subword-nmt/subword_nmt/apply_bpe.py:444: UserWarning: In parallel mode, the input cannot be STDIN. Using 1 processor instead.\n",
            "  warnings.warn(\"In parallel mode, the input cannot be STDIN. Using 1 processor instead.\")\n",
            "dev\n",
            "Apply to SRC corpus\n",
            "subword-nmt/subword_nmt/apply_bpe.py:444: UserWarning: In parallel mode, the input cannot be STDIN. Using 1 processor instead.\n",
            "  warnings.warn(\"In parallel mode, the input cannot be STDIN. Using 1 processor instead.\")\n",
            "Apply to TGT corpus\n",
            "subword-nmt/subword_nmt/apply_bpe.py:444: UserWarning: In parallel mode, the input cannot be STDIN. Using 1 processor instead.\n",
            "  warnings.warn(\"In parallel mode, the input cannot be STDIN. Using 1 processor instead.\")\n",
            "test\n",
            "Apply to SRC corpus\n",
            "subword-nmt/subword_nmt/apply_bpe.py:444: UserWarning: In parallel mode, the input cannot be STDIN. Using 1 processor instead.\n",
            "  warnings.warn(\"In parallel mode, the input cannot be STDIN. Using 1 processor instead.\")\n",
            "Apply to TGT corpus\n",
            "subword-nmt/subword_nmt/apply_bpe.py:444: UserWarning: In parallel mode, the input cannot be STDIN. Using 1 processor instead.\n",
            "  warnings.warn(\"In parallel mode, the input cannot be STDIN. Using 1 processor instead.\")\n",
            "Adding language tags\n",
            "930375it [00:07, 127130.70it/s]\n",
            "10000it [00:00, 172298.79it/s]\n",
            "23900it [00:00, 169037.61it/s]\n",
            "Binarizing data. This will take some time depending on the size of finetuning data\n",
            "2021-05-09 12:26:06 | INFO | fairseq_cli.preprocess | Namespace(align_suffix=None, alignfile=None, all_gather_list_size=16384, azureml_logging=False, bf16=False, bpe=None, cpu=False, criterion='cross_entropy', dataset_impl='mmap', destdir='../dataset/final_bin', empty_cache_freq=0, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, joined_dictionary=False, log_file=None, log_format=None, log_interval=100, lr_scheduler='fixed', memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_parallel_size=1, no_progress_bar=False, nwordssrc=-1, nwordstgt=-1, only_source=False, optimizer=None, padding_factor=8, plasma_path='/tmp/plasma', profile=False, quantization_config_path=None, reset_logging=False, scoring='bleu', seed=1, source_lang='SRC', srcdict='../en-indic/final_bin/dict.SRC.txt', suppress_crashes=False, target_lang='TGT', task='translation', tensorboard_logdir=None, testpref='../dataset/final/test', tgtdict='../en-indic/final_bin/dict.TGT.txt', threshold_loss_scale=None, thresholdsrc=5, thresholdtgt=5, tokenizer=None, tpu=False, trainpref='../dataset/final/train', use_plasma_view=False, user_dir=None, validpref='../dataset/final/dev', wandb_project=None, workers=2)\n",
            "2021-05-09 12:26:07 | INFO | fairseq_cli.preprocess | [SRC] Dictionary: 32104 types\n",
            "2021-05-09 12:28:32 | INFO | fairseq_cli.preprocess | [SRC] ../dataset/final/train.SRC: 930375 sents, 31481494 tokens, 0.0% replaced by <unk>\n",
            "2021-05-09 12:28:32 | INFO | fairseq_cli.preprocess | [SRC] Dictionary: 32104 types\n",
            "2021-05-09 12:28:33 | INFO | fairseq_cli.preprocess | [SRC] ../dataset/final/dev.SRC: 10000 sents, 222910 tokens, 0.117% replaced by <unk>\n",
            "2021-05-09 12:28:33 | INFO | fairseq_cli.preprocess | [SRC] Dictionary: 32104 types\n",
            "2021-05-09 12:28:36 | INFO | fairseq_cli.preprocess | [SRC] ../dataset/final/test.SRC: 23900 sents, 523960 tokens, 0.155% replaced by <unk>\n",
            "2021-05-09 12:28:36 | INFO | fairseq_cli.preprocess | [TGT] Dictionary: 35848 types\n",
            "2021-05-09 12:32:11 | INFO | fairseq_cli.preprocess | [TGT] ../dataset/final/train.TGT: 930375 sents, 35902065 tokens, 0.318% replaced by <unk>\n",
            "2021-05-09 12:32:11 | INFO | fairseq_cli.preprocess | [TGT] Dictionary: 35848 types\n",
            "2021-05-09 12:32:12 | INFO | fairseq_cli.preprocess | [TGT] ../dataset/final/dev.TGT: 10000 sents, 248776 tokens, 0.608% replaced by <unk>\n",
            "2021-05-09 12:32:12 | INFO | fairseq_cli.preprocess | [TGT] Dictionary: 35848 types\n",
            "2021-05-09 12:32:16 | INFO | fairseq_cli.preprocess | [TGT] ../dataset/final/test.TGT: 23900 sents, 582645 tokens, 0.557% replaced by <unk>\n",
            "2021-05-09 12:32:16 | INFO | fairseq_cli.preprocess | Wrote preprocessed data to ../dataset/final_bin\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              ""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iz6tzbe2tcs7",
        "outputId": "edbb1a47-1ee4-4f8b-d552-d741cfdb8857"
      },
      "source": [
        "# Finetuning the model\n",
        "\n",
        "# pls refer to fairseq documentaion to know more about each of these options (https://fairseq.readthedocs.io/en/latest/command_line_tools.html)\n",
        "\n",
        "\n",
        "# some notable args:\n",
        "# --max-update=1000     -> for this example, to demonstrate how to finetune we are only training for 1000 steps, incrase this if needed\n",
        "# --arch=transformer_4x -> we use a custom transformer model and name it transformer_4x (4 times the parameter size of transformer  base)\n",
        "# --user_dir            -> we define the custom transformer arch in model_configs folder and pass it as an argument to user_dir for fairseq to register this architechture\n",
        "# --lr                  -> learning rate. From our limited experiments, we find that lower learning rates like 3e-5 works best for finetuning.\n",
        "# --restore-file        -> reload the pretrained checkpoint and start training from here (change this path for indic-en. Currently its is set to en-indic)\n",
        "# --reset-*             -> reset and not use lr scheduler, dataloader, optimizer etc of the older checkpoint\n",
        "\n",
        "\n",
        "!( fairseq-train ../dataset/final_bin \\\n",
        "--max-source-positions=210 \\\n",
        "--max-target-positions=210 \\\n",
        "--max-update=1000 \\\n",
        "--save-interval=1 \\\n",
        "--arch=transformer_4x \\\n",
        "--criterion=label_smoothed_cross_entropy \\\n",
        "--source-lang=SRC \\\n",
        "--lr-scheduler=inverse_sqrt \\\n",
        "--target-lang=TGT \\\n",
        "--label-smoothing=0.1 \\\n",
        "--optimizer adam \\\n",
        "--adam-betas \"(0.9, 0.98)\" \\\n",
        "--clip-norm 1.0 \\\n",
        "--warmup-init-lr 1e-07 \\\n",
        "--warmup-updates 4000 \\\n",
        "--dropout 0.2 \\\n",
        "--tensorboard-logdir ../dataset/tensorboard-wandb \\\n",
        "--save-dir ../dataset/model \\\n",
        "--keep-last-epochs 5 \\\n",
        "--patience 5 \\\n",
        "--skip-invalid-size-inputs-valid-test \\\n",
        "--fp16 \\\n",
        "--user-dir model_configs \\\n",
        "--update-freq=2 \\\n",
        "--distributed-world-size 1 \\\n",
        "--max-tokens 16384 \\\n",
        "--lr 3e-5 \\\n",
        "--restore-file ../en-indic/model/checkpoint_best.pt \\\n",
        "--reset-lr-scheduler \\\n",
        "--reset-meters \\\n",
        "--reset-dataloader \\\n",
        "--reset-optimizer)"
      ],
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-05-09 12:51:46 | INFO | fairseq_cli.train | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': None, 'log_file': None, 'tensorboard_logdir': '../dataset/tensorboard-wandb', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'user_dir': 'model_configs', 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_algorithm': 'LocalSGD', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'distributed_num_procs': 0}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': True, 'max_tokens': 16384, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 16384, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 1000, 'stop_time_hours': 0.0, 'clip_norm': 1.0, 'sentence_avg': False, 'update_freq': [2], 'lr': [3e-05], 'stop_min_lr': -1.0, 'use_bmuf': False}, 'checkpoint': {'_name': None, 'save_dir': '../dataset/model', 'restore_file': 'checkpoint_last.pt', 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': True, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': 5, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': 5, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(_name='transformer_4x', activation_dropout=0.0, activation_fn='relu', adam_betas='(0.9, 0.98)', adam_eps=1e-08, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, all_gather_list_size=16384, arch='transformer_4x', attention_dropout=0.0, azureml_logging=False, batch_size=None, batch_size_valid=None, best_checkpoint_metric='loss', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_activations=False, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=1.0, cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy', cross_self_attention=False, curriculum=0, data='../dataset/final_bin', data_buffer_size=10, dataset_impl=None, ddp_backend='pytorch_ddp', ddp_comm_hook='none', decoder_attention_heads=16, decoder_embed_dim=1536, decoder_embed_path=None, decoder_ffn_embed_dim=4096, decoder_input_dim=1536, decoder_layerdrop=0, decoder_layers=6, decoder_layers_to_keep=None, decoder_learned_pos=False, decoder_normalize_before=False, decoder_output_dim=1536, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_port=-1, distributed_rank=0, distributed_world_size=1, dropout=0.2, empty_cache_freq=0, encoder_attention_heads=16, encoder_embed_dim=1536, encoder_embed_path=None, encoder_ffn_embed_dim=4096, encoder_layerdrop=0, encoder_layers=6, encoder_layers_to_keep=None, encoder_learned_pos=False, encoder_normalize_before=False, eos=2, eval_bleu=False, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_print_samples=False, eval_bleu_remove_bpe=None, eval_tokenized_bleu=False, fast_stat_sync=False, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, gen_subset='test', heartbeat_timeout=-1, ignore_prefix_size=0, keep_best_checkpoints=-1, keep_interval_updates=-1, keep_interval_updates_pattern=-1, keep_last_epochs=5, label_smoothing=0.1, layernorm_embedding=False, left_pad_source=True, left_pad_target=False, load_alignments=False, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lr=[3e-05], lr_scheduler='inverse_sqrt', max_epoch=0, max_source_positions=210, max_target_positions=210, max_tokens=16384, max_tokens_valid=16384, max_update=1000, max_valid_steps=None, maximize_best_checkpoint_metric=False, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, min_params_to_wrap=100000000, model_parallel_size=1, no_cross_attention=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_progress_bar=False, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, nprocs_per_node=1, num_batch_buckets=0, num_shards=1, num_workers=1, offload_activations=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=5, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', profile=False, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, quantization_config_path=None, report_accuracy=False, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=True, reset_logging=False, reset_lr_scheduler=True, reset_meters=True, reset_optimizer=True, restore_file='checkpoint_last.pt', save_dir='../dataset/model', save_interval=1, save_interval_updates=0, scoring='bleu', seed=1, sentence_avg=False, shard_id=0, share_all_embeddings=False, share_decoder_input_output_embed=False, skip_invalid_size_inputs_valid_test=True, slowmo_algorithm='LocalSGD', slowmo_momentum=None, source_lang='SRC', stop_min_lr=-1.0, stop_time_hours=0, suppress_crashes=False, target_lang='TGT', task='translation', tensorboard_logdir='../dataset/tensorboard-wandb', threshold_loss_scale=None, tie_adaptive_weights=False, tokenizer=None, tpu=False, train_subset='train', truncate_source=False, unk=3, update_freq=[2], upsample_primary=-1, use_bmuf=False, use_old_adam=False, use_plasma_view=False, user_dir='model_configs', valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, wandb_project=None, warmup_init_lr=1e-07, warmup_updates=4000, weight_decay=0.0, write_checkpoints_asynchronously=False, zero_sharding='none'), 'task': {'_name': 'translation', 'data': '../dataset/final_bin', 'source_lang': 'SRC', 'target_lang': 'TGT', 'load_alignments': False, 'left_pad_source': True, 'left_pad_target': False, 'max_source_positions': 210, 'max_target_positions': 210, 'upsample_primary': -1, 'truncate_source': False, 'num_batch_buckets': 0, 'train_subset': 'train', 'dataset_impl': None, 'required_seq_len_multiple': 1, 'eval_bleu': False, 'eval_bleu_args': '{}', 'eval_bleu_detok': 'space', 'eval_bleu_detok_args': '{}', 'eval_tokenized_bleu': False, 'eval_bleu_remove_bpe': None, 'eval_bleu_print_samples': False}, 'criterion': {'_name': 'label_smoothed_cross_entropy', 'label_smoothing': 0.1, 'report_accuracy': False, 'ignore_prefix_size': 0, 'sentence_avg': False}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.0, 'use_old_adam': False, 'tpu': False, 'lr': [3e-05]}, 'lr_scheduler': {'_name': 'inverse_sqrt', 'warmup_updates': 4000, 'warmup_init_lr': 1e-07, 'lr': [3e-05]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None}\n",
            "2021-05-09 12:51:46 | INFO | fairseq.tasks.translation | [SRC] dictionary: 32104 types\n",
            "2021-05-09 12:51:46 | INFO | fairseq.tasks.translation | [TGT] dictionary: 35848 types\n",
            "2021-05-09 12:51:56 | INFO | fairseq_cli.train | TransformerModel(\n",
            "  (encoder): TransformerEncoder(\n",
            "    (dropout_module): FairseqDropout()\n",
            "    (embed_tokens): Embedding(32104, 1536, padding_idx=1)\n",
            "    (embed_positions): SinusoidalPositionalEmbedding()\n",
            "    (layers): ModuleList(\n",
            "      (0): TransformerEncoderLayer(\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
            "          (v_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
            "          (q_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
            "          (out_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
            "        )\n",
            "        (self_attn_layer_norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (fc1): Linear(in_features=1536, out_features=4096, bias=True)\n",
            "        (fc2): Linear(in_features=4096, out_features=1536, bias=True)\n",
            "        (final_layer_norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (1): TransformerEncoderLayer(\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
            "          (v_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
            "          (q_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
            "          (out_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
            "        )\n",
            "        (self_attn_layer_norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (fc1): Linear(in_features=1536, out_features=4096, bias=True)\n",
            "        (fc2): Linear(in_features=4096, out_features=1536, bias=True)\n",
            "        (final_layer_norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (2): TransformerEncoderLayer(\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
            "          (v_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
            "          (q_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
            "          (out_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
            "        )\n",
            "        (self_attn_layer_norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (fc1): Linear(in_features=1536, out_features=4096, bias=True)\n",
            "        (fc2): Linear(in_features=4096, out_features=1536, bias=True)\n",
            "        (final_layer_norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (3): TransformerEncoderLayer(\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
            "          (v_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
            "          (q_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
            "          (out_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
            "        )\n",
            "        (self_attn_layer_norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (fc1): Linear(in_features=1536, out_features=4096, bias=True)\n",
            "        (fc2): Linear(in_features=4096, out_features=1536, bias=True)\n",
            "        (final_layer_norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (4): TransformerEncoderLayer(\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
            "          (v_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
            "          (q_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
            "          (out_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
            "        )\n",
            "        (self_attn_layer_norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (fc1): Linear(in_features=1536, out_features=4096, bias=True)\n",
            "        (fc2): Linear(in_features=4096, out_features=1536, bias=True)\n",
            "        (final_layer_norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (5): TransformerEncoderLayer(\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
            "          (v_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
            "          (q_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
            "          (out_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
            "        )\n",
            "        (self_attn_layer_norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (fc1): Linear(in_features=1536, out_features=4096, bias=True)\n",
            "        (fc2): Linear(in_features=4096, out_features=1536, bias=True)\n",
            "        (final_layer_norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (decoder): TransformerDecoder(\n",
            "    (dropout_module): FairseqDropout()\n",
            "    (embed_tokens): Embedding(35848, 1536, padding_idx=1)\n",
            "    (embed_positions): SinusoidalPositionalEmbedding()\n",
            "    (layers): ModuleList(\n",
            "      (0): TransformerDecoderLayer(\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
            "          (v_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
            "          (q_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
            "          (out_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
            "        )\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (self_attn_layer_norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
            "        (encoder_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
            "          (v_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
            "          (q_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
            "          (out_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
            "        )\n",
            "        (encoder_attn_layer_norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=1536, out_features=4096, bias=True)\n",
            "        (fc2): Linear(in_features=4096, out_features=1536, bias=True)\n",
            "        (final_layer_norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (1): TransformerDecoderLayer(\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
            "          (v_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
            "          (q_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
            "          (out_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
            "        )\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (self_attn_layer_norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
            "        (encoder_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
            "          (v_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
            "          (q_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
            "          (out_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
            "        )\n",
            "        (encoder_attn_layer_norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=1536, out_features=4096, bias=True)\n",
            "        (fc2): Linear(in_features=4096, out_features=1536, bias=True)\n",
            "        (final_layer_norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (2): TransformerDecoderLayer(\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
            "          (v_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
            "          (q_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
            "          (out_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
            "        )\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (self_attn_layer_norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
            "        (encoder_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
            "          (v_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
            "          (q_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
            "          (out_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
            "        )\n",
            "        (encoder_attn_layer_norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=1536, out_features=4096, bias=True)\n",
            "        (fc2): Linear(in_features=4096, out_features=1536, bias=True)\n",
            "        (final_layer_norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (3): TransformerDecoderLayer(\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
            "          (v_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
            "          (q_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
            "          (out_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
            "        )\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (self_attn_layer_norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
            "        (encoder_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
            "          (v_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
            "          (q_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
            "          (out_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
            "        )\n",
            "        (encoder_attn_layer_norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=1536, out_features=4096, bias=True)\n",
            "        (fc2): Linear(in_features=4096, out_features=1536, bias=True)\n",
            "        (final_layer_norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (4): TransformerDecoderLayer(\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
            "          (v_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
            "          (q_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
            "          (out_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
            "        )\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (self_attn_layer_norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
            "        (encoder_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
            "          (v_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
            "          (q_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
            "          (out_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
            "        )\n",
            "        (encoder_attn_layer_norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=1536, out_features=4096, bias=True)\n",
            "        (fc2): Linear(in_features=4096, out_features=1536, bias=True)\n",
            "        (final_layer_norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (5): TransformerDecoderLayer(\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
            "          (v_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
            "          (q_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
            "          (out_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
            "        )\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (self_attn_layer_norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
            "        (encoder_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
            "          (v_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
            "          (q_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
            "          (out_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
            "        )\n",
            "        (encoder_attn_layer_norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=1536, out_features=4096, bias=True)\n",
            "        (fc2): Linear(in_features=4096, out_features=1536, bias=True)\n",
            "        (final_layer_norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "    )\n",
            "    (output_projection): Linear(in_features=1536, out_features=35848, bias=False)\n",
            "  )\n",
            ")\n",
            "2021-05-09 12:51:56 | INFO | fairseq_cli.train | task: TranslationTask\n",
            "2021-05-09 12:51:56 | INFO | fairseq_cli.train | model: TransformerModel\n",
            "2021-05-09 12:51:56 | INFO | fairseq_cli.train | criterion: LabelSmoothedCrossEntropyCriterion\n",
            "2021-05-09 12:51:56 | INFO | fairseq_cli.train | num. shared model params: 480,571,392 (num. trained: 480,571,392)\n",
            "2021-05-09 12:51:56 | INFO | fairseq_cli.train | num. expert model params: 0 (num. trained: 0)\n",
            "2021-05-09 12:51:56 | INFO | fairseq.data.data_utils | loaded 10,000 examples from: ../dataset/final_bin/valid.SRC-TGT.SRC\n",
            "2021-05-09 12:51:56 | INFO | fairseq.data.data_utils | loaded 10,000 examples from: ../dataset/final_bin/valid.SRC-TGT.TGT\n",
            "2021-05-09 12:51:56 | INFO | fairseq.tasks.translation | ../dataset/final_bin valid SRC-TGT 10000 examples\n",
            "2021-05-09 12:51:57 | INFO | fairseq_cli.train | training on 1 devices (GPUs/TPUs)\n",
            "2021-05-09 12:51:57 | INFO | fairseq_cli.train | max tokens per device = 16384 and max sentences per device = None\n",
            "2021-05-09 12:51:57 | INFO | fairseq.trainer | Preparing to load checkpoint ../dataset/model/checkpoint_last.pt\n",
            "2021-05-09 12:51:57 | INFO | fairseq.trainer | No existing checkpoint found ../dataset/model/checkpoint_last.pt\n",
            "2021-05-09 12:51:57 | INFO | fairseq.trainer | loading train data for epoch 1\n",
            "2021-05-09 12:51:57 | INFO | fairseq.data.data_utils | loaded 930,375 examples from: ../dataset/final_bin/train.SRC-TGT.SRC\n",
            "2021-05-09 12:51:57 | INFO | fairseq.data.data_utils | loaded 930,375 examples from: ../dataset/final_bin/train.SRC-TGT.TGT\n",
            "2021-05-09 12:51:57 | INFO | fairseq.tasks.translation | ../dataset/final_bin train SRC-TGT 930375 examples\n",
            "2021-05-09 12:51:57 | WARNING | fairseq.tasks.fairseq_task | 1,647 samples have invalid sizes and will be skipped, max_positions=(210, 210), first few sample ids=[865604, 927195, 465934, 204968, 865293, 859052, 1713, 672173, 858328, 286278]\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/fairseq-train\", line 33, in <module>\n",
            "    sys.exit(load_entry_point('fairseq', 'console_scripts', 'fairseq-train')())\n",
            "  File \"/content/finetuning/fairseq/fairseq_cli/train.py\", line 496, in cli_main\n",
            "    distributed_utils.call_main(cfg, main)\n",
            "  File \"/content/finetuning/fairseq/fairseq/distributed/utils.py\", line 369, in call_main\n",
            "    main(cfg, **kwargs)\n",
            "  File \"/content/finetuning/fairseq/fairseq_cli/train.py\", line 153, in main\n",
            "    disable_iterator_cache=task.has_sharded_data(\"train\"),\n",
            "  File \"/content/finetuning/fairseq/fairseq/checkpoint_utils.py\", line 241, in load_checkpoint\n",
            "    trainer.lr_step(epoch_itr.epoch)\n",
            "  File \"/content/finetuning/fairseq/fairseq/trainer.py\", line 961, in lr_step\n",
            "    self.lr_scheduler.step(epoch, val_loss)\n",
            "  File \"/content/finetuning/fairseq/fairseq/trainer.py\", line 251, in lr_scheduler\n",
            "    self._build_optimizer()  # this will initialize self._lr_scheduler\n",
            "  File \"/content/finetuning/fairseq/fairseq/trainer.py\", line 289, in _build_optimizer\n",
            "    self._optimizer = optim.FP16Optimizer.build_optimizer(self.cfg, params)\n",
            "  File \"/content/finetuning/fairseq/fairseq/optim/fp16_optimizer.py\", line 291, in build_optimizer\n",
            "    fp32_params = cls.build_fp32_params(cfg.optimizer, params, flatten=flatten)\n",
            "  File \"/content/finetuning/fairseq/fairseq/optim/fp16_optimizer.py\", line 37, in build_fp32_params\n",
            "    devices = [torch.cuda.current_device()]\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/cuda/__init__.py\", line 388, in current_device\n",
            "    _lazy_init()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/cuda/__init__.py\", line 170, in _lazy_init\n",
            "    torch._C._cuda_init()\n",
            "RuntimeError: No CUDA GPUs are available\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tpPsT1e7vuO9"
      },
      "source": [
        "# To test the models after training, you can use joint_translate.sh\n",
        "\n",
        "\n",
        "\n",
        "# joint_translate takes src_file, output_fname, src_lang, tgt_lang, model_folder as inputs\n",
        "# src_file -> input text file to be translated\n",
        "# output_fname -> name of the output file (will get created) containing the model predictions\n",
        "# src_lang -> source lang code of the input text ( in this case we are using en-indic model and hence src_lang would be 'en')\n",
        "# tgt_lang -> target lang code of the input text ( tgt lang for en-indic model would be any of the 11 indic langs we trained on:\n",
        "#              as, bn, hi, gu, kn, ml, mr, or, pa, ta, te)\n",
        "# supported languages are:\n",
        "#              as - assamese, bn - bengali, gu - gujarathi, hi - hindi, kn - kannada, \n",
        "#              ml - malayalam, mr - marathi, or - oriya, pa - punjabi, ta - tamil, te - telugu\n",
        "\n",
        "# model_dir -> the directory containing the model and the vocab files\n",
        "\n",
        "# Note: if the translation is taking a lot of time, please tune the buffer_size and batch_size parameter for fairseq-interactive defined inside this joint_translate script\n",
        "\n",
        "\n",
        "# here we are translating the english sentences to hindi\n",
        "!bash joint_translate.sh $exp_dir/test/test.en en_hi_outputs.txt 'en' 'hi' $exp_dir"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bPqneByPxilN"
      },
      "source": [
        "# to compute bleu scores for the predicitions with a reference file, use the following command\n",
        "# arguments:\n",
        "# pred_fname: file that contains model predictions\n",
        "# ref_fname: file that contains references\n",
        "# src_lang and tgt_lang : the source and target language\n",
        "\n",
        "bash compute_bleu.sh en_hi_outputs.txt $exp_dir/test/test.hi 'en' 'hi'\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
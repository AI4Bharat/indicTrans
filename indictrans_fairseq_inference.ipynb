{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "indictrans_fairseq_inference.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNehD2avkbcN8w2gmcKWkqF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gowtham1997/indicTrans/blob/main/indictrans_fairseq_inference.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P0uptOB6U7GW",
        "outputId": "21bc585e-6bd7-4c43-b107-74c33de89a8d"
      },
      "source": [
        "# create a seperate folder to store everything\n",
        "!mkdir testing\n",
        "%cd testing"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/testing\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kQFRiLtSalzt",
        "outputId": "550f5836-de68-4f91-b319-e7e33cd17f83"
      },
      "source": [
        "# clone the repo for running evaluation\n",
        "!git clone https://github.com/AI4Bharat/indicTrans.git\n",
        "%cd IndicTrans_evaluation\n",
        "# clone requirements repositories\n",
        "!git clone https://github.com/anoopkunchukuttan/indic_nlp_library.git\n",
        "!git clone https://github.com/anoopkunchukuttan/indic_nlp_resources.git\n",
        "!git clone https://github.com/rsennrich/subword-nmt.git\n",
        "%cd .."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'IndicTrans_evaluation'...\n",
            "remote: Enumerating objects: 21, done.\u001b[K\n",
            "remote: Counting objects: 100% (21/21), done.\u001b[K\n",
            "remote: Compressing objects: 100% (15/15), done.\u001b[K\n",
            "remote: Total 21 (delta 3), reused 21 (delta 3), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (21/21), done.\n",
            "/content/testing/IndicTrans_evaluation\n",
            "Cloning into 'indic_nlp_library'...\n",
            "remote: Enumerating objects: 93, done.\u001b[K\n",
            "remote: Counting objects: 100% (93/93), done.\u001b[K\n",
            "remote: Compressing objects: 100% (68/68), done.\u001b[K\n",
            "remote: Total 1271 (delta 50), reused 54 (delta 25), pack-reused 1178\u001b[K\n",
            "Receiving objects: 100% (1271/1271), 9.56 MiB | 12.32 MiB/s, done.\n",
            "Resolving deltas: 100% (654/654), done.\n",
            "Cloning into 'indic_nlp_resources'...\n",
            "remote: Enumerating objects: 7, done.\u001b[K\n",
            "remote: Counting objects: 100% (7/7), done.\u001b[K\n",
            "remote: Compressing objects: 100% (7/7), done.\u001b[K\n",
            "remote: Total 133 (delta 0), reused 2 (delta 0), pack-reused 126\u001b[K\n",
            "Receiving objects: 100% (133/133), 149.77 MiB | 25.53 MiB/s, done.\n",
            "Resolving deltas: 100% (51/51), done.\n",
            "Checking out files: 100% (28/28), done.\n",
            "Cloning into 'subword-nmt'...\n",
            "remote: Enumerating objects: 4, done.\u001b[K\n",
            "remote: Counting objects: 100% (4/4), done.\u001b[K\n",
            "remote: Compressing objects: 100% (4/4), done.\u001b[K\n",
            "remote: Total 580 (delta 0), reused 0 (delta 0), pack-reused 576\u001b[K\n",
            "Receiving objects: 100% (580/580), 237.41 KiB | 2.97 MiB/s, done.\n",
            "Resolving deltas: 100% (349/349), done.\n",
            "/content/testing\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FHUQGCACVvVf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5bac3189-075b-4f6a-db9e-caf0927d89b4"
      },
      "source": [
        "# Install the necessary libraries\n",
        "!pip install sacremoses pandas mock sacrebleu tensorboardX pyarrow indic-nlp-library\n",
        "# Install fairseq from source\n",
        "!git clone https://github.com/pytorch/fairseq.git\n",
        "%cd fairseq\n",
        "# !git checkout da9eaba12d82b9bfc1442f0e2c6fc1b895f4d35d\n",
        "!pip install --editable ./\n",
        "%cd .."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/08/cd/342e584ee544d044fb573ae697404ce22ede086c9e87ce5960772084cad0/sacremoses-0.0.44.tar.gz (862kB)\n",
            "\r\u001b[K     |▍                               | 10kB 18.1MB/s eta 0:00:01\r\u001b[K     |▊                               | 20kB 22.1MB/s eta 0:00:01\r\u001b[K     |█▏                              | 30kB 26.7MB/s eta 0:00:01\r\u001b[K     |█▌                              | 40kB 24.8MB/s eta 0:00:01\r\u001b[K     |██                              | 51kB 17.2MB/s eta 0:00:01\r\u001b[K     |██▎                             | 61kB 19.4MB/s eta 0:00:01\r\u001b[K     |██▋                             | 71kB 11.5MB/s eta 0:00:01\r\u001b[K     |███                             | 81kB 12.6MB/s eta 0:00:01\r\u001b[K     |███▍                            | 92kB 12.9MB/s eta 0:00:01\r\u001b[K     |███▉                            | 102kB 12.6MB/s eta 0:00:01\r\u001b[K     |████▏                           | 112kB 12.6MB/s eta 0:00:01\r\u001b[K     |████▋                           | 122kB 12.6MB/s eta 0:00:01\r\u001b[K     |█████                           | 133kB 12.6MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 143kB 12.6MB/s eta 0:00:01\r\u001b[K     |█████▊                          | 153kB 12.6MB/s eta 0:00:01\r\u001b[K     |██████                          | 163kB 12.6MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 174kB 12.6MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 184kB 12.6MB/s eta 0:00:01\r\u001b[K     |███████▏                        | 194kB 12.6MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 204kB 12.6MB/s eta 0:00:01\r\u001b[K     |████████                        | 215kB 12.6MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 225kB 12.6MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 235kB 12.6MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 245kB 12.6MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 256kB 12.6MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 266kB 12.6MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 276kB 12.6MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 286kB 12.6MB/s eta 0:00:01\r\u001b[K     |███████████                     | 296kB 12.6MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 307kB 12.6MB/s eta 0:00:01\r\u001b[K     |███████████▉                    | 317kB 12.6MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 327kB 12.6MB/s eta 0:00:01\r\u001b[K     |████████████▌                   | 337kB 12.6MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 348kB 12.6MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 358kB 12.6MB/s eta 0:00:01\r\u001b[K     |█████████████▊                  | 368kB 12.6MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 378kB 12.6MB/s eta 0:00:01\r\u001b[K     |██████████████▍                 | 389kB 12.6MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 399kB 12.6MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 409kB 12.6MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 419kB 12.6MB/s eta 0:00:01\r\u001b[K     |████████████████                | 430kB 12.6MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 440kB 12.6MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 450kB 12.6MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 460kB 12.6MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 471kB 12.6MB/s eta 0:00:01\r\u001b[K     |█████████████████▉              | 481kB 12.6MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 491kB 12.6MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 501kB 12.6MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 512kB 12.6MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 522kB 12.6MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 532kB 12.6MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 542kB 12.6MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 552kB 12.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 563kB 12.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 573kB 12.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 583kB 12.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 593kB 12.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████▍         | 604kB 12.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████▉         | 614kB 12.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 624kB 12.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 634kB 12.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 645kB 12.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 655kB 12.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 665kB 12.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 675kB 12.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 686kB 12.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 696kB 12.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 706kB 12.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▋     | 716kB 12.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 727kB 12.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▍    | 737kB 12.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▊    | 747kB 12.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 757kB 12.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 768kB 12.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 778kB 12.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▎  | 788kB 12.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▋  | 798kB 12.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 808kB 12.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 819kB 12.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 829kB 12.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 839kB 12.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 849kB 12.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 860kB 12.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 870kB 12.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (1.1.5)\n",
            "Collecting mock\n",
            "  Downloading https://files.pythonhosted.org/packages/5c/03/b7e605db4a57c0f6fba744b11ef3ddf4ddebcada35022927a2b5fc623fdf/mock-4.0.3-py3-none-any.whl\n",
            "Collecting sacrebleu\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7e/57/0c7ca4e31a126189dab99c19951910bd081dea5bbd25f24b77107750eae7/sacrebleu-1.5.1-py3-none-any.whl (54kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 6.3MB/s \n",
            "\u001b[?25hCollecting tensorboardX\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/07/84/46421bd3e0e89a92682b1a38b40efc22dafb6d8e3d947e4ceefd4a5fabc7/tensorboardX-2.2-py2.py3-none-any.whl (120kB)\n",
            "\u001b[K     |████████████████████████████████| 122kB 29.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyarrow in /usr/local/lib/python3.7/dist-packages (3.0.0)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from sacremoses) (2019.12.20)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses) (1.0.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from sacremoses) (4.41.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (2.8.1)\n",
            "Requirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.7/dist-packages (from pandas) (1.19.5)\n",
            "Collecting portalocker==2.0.0\n",
            "  Downloading https://files.pythonhosted.org/packages/89/a6/3814b7107e0788040870e8825eebf214d72166adf656ba7d4bf14759a06a/portalocker-2.0.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.7/dist-packages (from tensorboardX) (3.12.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.8.0->tensorboardX) (54.2.0)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.44-cp37-none-any.whl size=886084 sha256=720de8c556f500516ba275cdf1c76f250a77e2b2461bd86bbb1e3458a1f1a24e\n",
            "  Stored in directory: /root/.cache/pip/wheels/3e/fb/c0/13ab4d63d537658f448366744654323077c4d90069b6512f3c\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: sacremoses, mock, portalocker, sacrebleu, tensorboardX\n",
            "Successfully installed mock-4.0.3 portalocker-2.0.0 sacrebleu-1.5.1 sacremoses-0.0.44 tensorboardX-2.2\n",
            "Cloning into 'fairseq'...\n",
            "remote: Enumerating objects: 27579, done.\u001b[K\n",
            "remote: Total 27579 (delta 0), reused 0 (delta 0), pack-reused 27579\u001b[K\n",
            "Receiving objects: 100% (27579/27579), 11.43 MiB | 7.93 MiB/s, done.\n",
            "Resolving deltas: 100% (20815/20815), done.\n",
            "/content/testing/fairseq\n",
            "Obtaining file:///content/testing/fairseq\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting hydra-core<1.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/52/e3/fbd70dd0d3ce4d1d75c22d56c0c9f895cfa7ed6587a9ffb821d6812d6a60/hydra_core-1.0.6-py3-none-any.whl (123kB)\n",
            "\u001b[K     |████████████████████████████████| 133kB 10.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from fairseq==1.0.0a0+ee0d5a0) (2019.12.20)\n",
            "Requirement already satisfied: sacrebleu>=1.4.12 in /usr/local/lib/python3.7/dist-packages (from fairseq==1.0.0a0+ee0d5a0) (1.5.1)\n",
            "Requirement already satisfied: numpy; python_version >= \"3.7\" in /usr/local/lib/python3.7/dist-packages (from fairseq==1.0.0a0+ee0d5a0) (1.19.5)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from fairseq==1.0.0a0+ee0d5a0) (1.8.1+cu101)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from fairseq==1.0.0a0+ee0d5a0) (4.41.1)\n",
            "Collecting omegaconf<2.1\n",
            "  Downloading https://files.pythonhosted.org/packages/d0/eb/9d63ce09dd8aa85767c65668d5414958ea29648a0eec80a4a7d311ec2684/omegaconf-2.0.6-py3-none-any.whl\n",
            "Requirement already satisfied: cython in /usr/local/lib/python3.7/dist-packages (from fairseq==1.0.0a0+ee0d5a0) (0.29.22)\n",
            "Requirement already satisfied: cffi in /usr/local/lib/python3.7/dist-packages (from fairseq==1.0.0a0+ee0d5a0) (1.14.5)\n",
            "Collecting antlr4-python3-runtime==4.8\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/56/02/789a0bddf9c9b31b14c3e79ec22b9656185a803dc31c15f006f9855ece0d/antlr4-python3-runtime-4.8.tar.gz (112kB)\n",
            "\u001b[K     |████████████████████████████████| 112kB 18.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-resources; python_version < \"3.9\" in /usr/local/lib/python3.7/dist-packages (from hydra-core<1.1->fairseq==1.0.0a0+ee0d5a0) (5.1.2)\n",
            "Requirement already satisfied: portalocker==2.0.0 in /usr/local/lib/python3.7/dist-packages (from sacrebleu>=1.4.12->fairseq==1.0.0a0+ee0d5a0) (2.0.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch->fairseq==1.0.0a0+ee0d5a0) (3.7.4.3)\n",
            "Collecting PyYAML>=5.1.*\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7a/a5/393c087efdc78091afa2af9f1378762f9821c9c1d7a22c5753fb5ac5f97a/PyYAML-5.4.1-cp37-cp37m-manylinux1_x86_64.whl (636kB)\n",
            "\u001b[K     |████████████████████████████████| 645kB 16.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi->fairseq==1.0.0a0+ee0d5a0) (2.20)\n",
            "Requirement already satisfied: zipp>=0.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-resources; python_version < \"3.9\"->hydra-core<1.1->fairseq==1.0.0a0+ee0d5a0) (3.4.1)\n",
            "Building wheels for collected packages: antlr4-python3-runtime\n",
            "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.8-cp37-none-any.whl size=141231 sha256=e886d8bccaeab946480ae30d0cb355b89037754b7b04424a685568ccd834c0aa\n",
            "  Stored in directory: /root/.cache/pip/wheels/e3/e2/fa/b78480b448b8579ddf393bebd3f47ee23aa84c89b6a78285c8\n",
            "Successfully built antlr4-python3-runtime\n",
            "Installing collected packages: antlr4-python3-runtime, PyYAML, omegaconf, hydra-core, fairseq\n",
            "  Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "  Running setup.py develop for fairseq\n",
            "Successfully installed PyYAML-5.4.1 antlr4-python3-runtime-4.8 fairseq hydra-core-1.0.6 omegaconf-2.0.6\n",
            "/content/testing\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kKA8afhBawO5",
        "outputId": "3578d6bb-62f8-46c0-846e-8ce52315c02b"
      },
      "source": [
        "# download the indictrans model\n",
        "# in this notebook, we will be testing the indictrans-en-indic model\n",
        "# To test the indic-en model, pls use this link ->  https://storage.googleapis.com/samanantar-public/models/indictrans-indic-en.zip\n",
        "\n",
        "!wget https://storage.googleapis.com/samanantar-public/models/indictrans-en-indic.zip\n",
        "!unzip indictrans-en-indic.zip\n",
        "%cd IndicTrans_evaluation/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-04-12 14:13:49--  https://storage.googleapis.com/samanantar-public/models/indictrans-en-indic.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 108.177.127.128, 172.217.218.128, 108.177.126.128, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|108.177.127.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4382161679 (4.1G) [application/zip]\n",
            "Saving to: ‘indictrans-en-indic.zip’\n",
            "\n",
            "indictrans-en-indic 100%[===================>]   4.08G  69.0MB/s    in 53s     \n",
            "\n",
            "2021-04-12 14:14:43 (78.8 MB/s) - ‘indictrans-en-indic.zip’ saved [4382161679/4382161679]\n",
            "\n",
            "Archive:  indictrans-en-indic.zip\n",
            "   creating: indictrans-en-indic/\n",
            "   creating: indictrans-en-indic/final_bin/\n",
            "  inflating: indictrans-en-indic/final_bin/dict.SRC.txt  \n",
            "  inflating: indictrans-en-indic/final_bin/dict.TGT.txt  \n",
            "   creating: indictrans-en-indic/model/\n",
            "  inflating: indictrans-en-indic/model/checkpoint_best.pt  \n",
            "   creating: indictrans-en-indic/vocab/\n",
            "  inflating: indictrans-en-indic/vocab/vocab.SRC  \n",
            "  inflating: indictrans-en-indic/vocab/vocab.tmp.SRC  \n",
            "  inflating: indictrans-en-indic/vocab/vocab.TGT  \n",
            "  inflating: indictrans-en-indic/vocab/vocab.tmp.TGT  \n",
            "  inflating: indictrans-en-indic/vocab/bpe_codes.32k.SRC_TGT  \n",
            "/content/testing/IndicTrans_evaluation\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lg1sQFfyWJli"
      },
      "source": [
        "# creating a text file and adding en sentences we can use for testing the model\n",
        "!touch en_sentences.txt\n",
        "!echo 'This bicycle is too small for you!!' >> en_sentences.txt\n",
        "!echo ' I am running late. Meet you directly at the airport' >> en_sentences.txt\n",
        "!echo 'In 2006, Time magazine stated that the open-door policy of allowing anyone to edit had made Wikipedia the \"biggest and perhaps the best encyclopedia in the world\", and a testament to the vision of Jimmy Walest' >> en_sentences.txt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fLg9BWAGWvLU",
        "outputId": "2846d784-61be-4532-eefd-fc35f74d338c"
      },
      "source": [
        "# joint_translate takes src_file, output_fname, src_lang, tgt_lang, model_folder as inputs\n",
        "# src_file -> input text file to be translated\n",
        "# output_fname -> name of the output file (will get created) containing the model predictions\n",
        "# src_lang -> source lang code of the input text ( in this case we are using en-indic model and hence src_lang would be 'en')\n",
        "# tgt_lang -> target lang code of the input text ( tgt lang for en-indic model would be any of the 11 indic langs we trained on:\n",
        "#              as, bn, hi, gu, kn, ml, mr, or, pa, ta, te)\n",
        "# supported languages are:\n",
        "#              as - assamese, bn - bengali, gu - gujarathi, hi - hindi, kn - kannada, \n",
        "#              ml - malayalam, mr - marathi, or - oriya, pa - punjabi, ta - tamil, te - telugu\n",
        "\n",
        "# model_dir -> the directory containing the model and the vocab files\n",
        "\n",
        "# Note: if the translation is taking a lot of time, please tune the buffer_size and batch_size parameter for fairseq-interactive defined inside this joint_translate script\n",
        "\n",
        "\n",
        "# here we are translating the english sentences to tamil\n",
        "!bash joint_translate.sh en_sentences.txt ta_outputs.txt 'en' 'ta' '../indictrans-en-indic'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mon Apr 12 14:35:44 UTC 2021\n",
            "Applying normalization and script conversion\n",
            "100% 3/3 [00:00<00:00, 58.78it/s]\n",
            "Number of sentences in input: 3\n",
            "Applying BPE\n",
            "Decoding\n",
            "Extracting translations, script conversion and detokenization\n",
            "Mon Apr 12 14:37:59 UTC 2021\n",
            "Translation completed\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "28ULSe4GY6tE",
        "outputId": "5c49b7b3-3878-4faf-ebd7-3e0188f18b0a"
      },
      "source": [
        "# see the model outputs saved in ta_outputs.txt\n",
        "!cat ta_outputs.txt"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "இந்த சைக்கிள் ரொம்ப சிறியது!\n",
            "நான் தாமதமாக வருகிறேன். விமான நிலையத்தில் நேரடியாக உங்களை சந்திக்கிறேன்.\n",
            "2006 ஆம் ஆண்டில், டைம் பத்திரிகை, எவரை எடிட் செய்ய அனுமதிக்கும் திறந்த கதவு கொள்கை, விக்கிப்பீடியாவை \"உலகின் மிகப்பெரிய மற்றும் ஒருவேளை சிறந்த கலைக்களஞ்சியமாக\" மாற்றியது, மேலும் ஜிம்மி வாலஸ்டின் தொலைநோக்குப் பார்வைக்கு ஒரு சான்றாக இருந்தது என்று கூறியது.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c4v9BmbZao5d",
        "outputId": "a0723e55-92f9-4f77-c6ab-cf0a1f0f1558"
      },
      "source": [
        "# Similarly, we can translate the english sentences to hindi\n",
        "!bash joint_translate.sh en_sentences.txt hi_outputs.txt 'en' 'hi' '../indictrans-en-indic'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mon Apr 12 14:39:07 UTC 2021\n",
            "Applying normalization and script conversion\n",
            "100% 3/3 [00:00<00:00, 54.43it/s]\n",
            "Number of sentences in input: 3\n",
            "Applying BPE\n",
            "Decoding\n",
            "Extracting translations, script conversion and detokenization\n",
            "Mon Apr 12 14:41:21 UTC 2021\n",
            "Translation completed\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pNNzyR_LfqIr",
        "outputId": "fa7a7e31-7491-4c45-f929-d94b8c560caf"
      },
      "source": [
        "!cat hi_outputs.txt"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "यह साइकिल तुम्हारे लिए बहुत छोटी है!\n",
            "मैं देर से आ रहा हूं, एयरपोर्ट पर आपसे सीधे मिलूंगा\n",
            "2006 में, टाइम पत्रिका ने कहा कि किसी को भी संपादित करने की अनुमति देने की ओपन-डोर नीति ने विकिपीडिया को \"दुनिया का सबसे बड़ा और शायद सबसे अच्छा विश्वकोश\" बना दिया था, और जिमी वालेस्ट के दृष्टिकोण का एक वसीयतनामा बना दिया था।\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-xcnDOc4gNKC"
      },
      "source": [
        "# to compute bleu scores for the predicitions with a reference file, use the following command\n",
        "\n",
        "# bash compute_bleu.sh pred_fname ref_fname src_lang tgt_lang\n",
        "# arguments:\n",
        "# pred_fname: file that contains model predictions\n",
        "# ref_fname: file that contains references\n",
        "# src_lang and tgt_lang : the source and target language"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9YK2BdwvrUgI"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
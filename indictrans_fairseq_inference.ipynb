{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "indictrans_fairseq_inference.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOamP/9tephUHmTAsg8UTDh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gowtham1997/indicTrans-1/blob/patch-1/indictrans_fairseq_inference.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P0uptOB6U7GW",
        "outputId": "65b7cfb4-127f-4dd2-909c-67e42867b6a7"
      },
      "source": [
        "# create a seperate folder to store everything\n",
        "!mkdir testing\n",
        "%cd testing"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/testing\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kQFRiLtSalzt",
        "outputId": "30a91d2a-c08c-4b88-d3f5-4bf4f86c853c"
      },
      "source": [
        "# clone the repo for running evaluation\n",
        "!git clone https://github.com/AI4Bharat/indicTrans.git\n",
        "%cd indicTrans\n",
        "# clone requirements repositories\n",
        "!git clone https://github.com/anoopkunchukuttan/indic_nlp_library.git\n",
        "!git clone https://github.com/anoopkunchukuttan/indic_nlp_resources.git\n",
        "!git clone https://github.com/rsennrich/subword-nmt.git\n",
        "%cd .."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'indicTrans'...\n",
            "remote: Enumerating objects: 366, done.\u001b[K\n",
            "remote: Counting objects: 100% (366/366), done.\u001b[K\n",
            "remote: Compressing objects: 100% (237/237), done.\u001b[K\n",
            "remote: Total 366 (delta 212), reused 251 (delta 125), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (366/366), 1.38 MiB | 5.80 MiB/s, done.\n",
            "Resolving deltas: 100% (212/212), done.\n",
            "/content/testing/indicTrans\n",
            "Cloning into 'indic_nlp_library'...\n",
            "remote: Enumerating objects: 1271, done.\u001b[K\n",
            "remote: Counting objects: 100% (93/93), done.\u001b[K\n",
            "remote: Compressing objects: 100% (68/68), done.\u001b[K\n",
            "remote: Total 1271 (delta 50), reused 54 (delta 25), pack-reused 1178\u001b[K\n",
            "Receiving objects: 100% (1271/1271), 9.56 MiB | 12.94 MiB/s, done.\n",
            "Resolving deltas: 100% (654/654), done.\n",
            "Cloning into 'indic_nlp_resources'...\n",
            "remote: Enumerating objects: 133, done.\u001b[K\n",
            "remote: Counting objects: 100% (7/7), done.\u001b[K\n",
            "remote: Compressing objects: 100% (7/7), done.\u001b[K\n",
            "remote: Total 133 (delta 0), reused 2 (delta 0), pack-reused 126\u001b[K\n",
            "Receiving objects: 100% (133/133), 149.77 MiB | 33.79 MiB/s, done.\n",
            "Resolving deltas: 100% (51/51), done.\n",
            "Checking out files: 100% (28/28), done.\n",
            "Cloning into 'subword-nmt'...\n",
            "remote: Enumerating objects: 580, done.\u001b[K\n",
            "remote: Counting objects: 100% (4/4), done.\u001b[K\n",
            "remote: Compressing objects: 100% (4/4), done.\u001b[K\n",
            "remote: Total 580 (delta 0), reused 0 (delta 0), pack-reused 576\u001b[K\n",
            "Receiving objects: 100% (580/580), 237.41 KiB | 5.93 MiB/s, done.\n",
            "Resolving deltas: 100% (349/349), done.\n",
            "/content/testing\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FHUQGCACVvVf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "58dd3401-810c-413f-cae3-7067a5f05b72"
      },
      "source": [
        "# Install the necessary libraries\n",
        "!pip install sacremoses pandas mock sacrebleu tensorboardX pyarrow indic-nlp-library\n",
        "# Install fairseq from source\n",
        "!git clone https://github.com/pytorch/fairseq.git\n",
        "%cd fairseq\n",
        "# !git checkout da9eaba12d82b9bfc1442f0e2c6fc1b895f4d35d\n",
        "!pip install --editable ./\n",
        "%cd .."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/75/ee/67241dc87f266093c533a2d4d3d69438e57d7a90abb216fa076e7d475d4a/sacremoses-0.0.45-py3-none-any.whl (895kB)\n",
            "\u001b[K     |████████████████████████████████| 901kB 5.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (1.1.5)\n",
            "Collecting mock\n",
            "  Downloading https://files.pythonhosted.org/packages/5c/03/b7e605db4a57c0f6fba744b11ef3ddf4ddebcada35022927a2b5fc623fdf/mock-4.0.3-py3-none-any.whl\n",
            "Collecting sacrebleu\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7e/57/0c7ca4e31a126189dab99c19951910bd081dea5bbd25f24b77107750eae7/sacrebleu-1.5.1-py3-none-any.whl (54kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 6.6MB/s \n",
            "\u001b[?25hCollecting tensorboardX\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/07/84/46421bd3e0e89a92682b1a38b40efc22dafb6d8e3d947e4ceefd4a5fabc7/tensorboardX-2.2-py2.py3-none-any.whl (120kB)\n",
            "\u001b[K     |████████████████████████████████| 122kB 14.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyarrow in /usr/local/lib/python3.7/dist-packages (3.0.0)\n",
            "Collecting indic-nlp-library\n",
            "  Downloading https://files.pythonhosted.org/packages/2f/51/f4e4542a226055b73a621ad442c16ae2c913d6b497283c99cae7a9661e6c/indic_nlp_library-0.71-py3-none-any.whl\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses) (1.15.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from sacremoses) (4.41.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses) (1.0.1)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from sacremoses) (2019.12.20)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas) (2018.9)\n",
            "Requirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.7/dist-packages (from pandas) (1.19.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (2.8.1)\n",
            "Collecting portalocker==2.0.0\n",
            "  Downloading https://files.pythonhosted.org/packages/89/a6/3814b7107e0788040870e8825eebf214d72166adf656ba7d4bf14759a06a/portalocker-2.0.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.7/dist-packages (from tensorboardX) (3.12.4)\n",
            "Collecting morfessor\n",
            "  Downloading https://files.pythonhosted.org/packages/39/e6/7afea30be2ee4d29ce9de0fa53acbb033163615f849515c0b1956ad074ee/Morfessor-2.0.6-py3-none-any.whl\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.8.0->tensorboardX) (56.0.0)\n",
            "Installing collected packages: sacremoses, mock, portalocker, sacrebleu, tensorboardX, morfessor, indic-nlp-library\n",
            "Successfully installed indic-nlp-library-0.71 mock-4.0.3 morfessor-2.0.6 portalocker-2.0.0 sacrebleu-1.5.1 sacremoses-0.0.45 tensorboardX-2.2\n",
            "Cloning into 'fairseq'...\n",
            "remote: Enumerating objects: 27747, done.\u001b[K\n",
            "remote: Counting objects: 100% (168/168), done.\u001b[K\n",
            "remote: Compressing objects: 100% (93/93), done.\u001b[K\n",
            "remote: Total 27747 (delta 87), reused 117 (delta 75), pack-reused 27579\u001b[K\n",
            "Receiving objects: 100% (27747/27747), 11.61 MiB | 23.73 MiB/s, done.\n",
            "Resolving deltas: 100% (20908/20908), done.\n",
            "/content/testing/fairseq\n",
            "Obtaining file:///content/testing/fairseq\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from fairseq==1.0.0a0+d6855ba) (4.41.1)\n",
            "Requirement already satisfied: sacrebleu>=1.4.12 in /usr/local/lib/python3.7/dist-packages (from fairseq==1.0.0a0+d6855ba) (1.5.1)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from fairseq==1.0.0a0+d6855ba) (2019.12.20)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from fairseq==1.0.0a0+d6855ba) (1.8.1+cu101)\n",
            "Requirement already satisfied: cython in /usr/local/lib/python3.7/dist-packages (from fairseq==1.0.0a0+d6855ba) (0.29.22)\n",
            "Collecting hydra-core<1.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/52/e3/fbd70dd0d3ce4d1d75c22d56c0c9f895cfa7ed6587a9ffb821d6812d6a60/hydra_core-1.0.6-py3-none-any.whl (123kB)\n",
            "\u001b[K     |████████████████████████████████| 133kB 5.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy; python_version >= \"3.7\" in /usr/local/lib/python3.7/dist-packages (from fairseq==1.0.0a0+d6855ba) (1.19.5)\n",
            "Collecting omegaconf<2.1\n",
            "  Downloading https://files.pythonhosted.org/packages/d0/eb/9d63ce09dd8aa85767c65668d5414958ea29648a0eec80a4a7d311ec2684/omegaconf-2.0.6-py3-none-any.whl\n",
            "Requirement already satisfied: cffi in /usr/local/lib/python3.7/dist-packages (from fairseq==1.0.0a0+d6855ba) (1.14.5)\n",
            "Requirement already satisfied: portalocker==2.0.0 in /usr/local/lib/python3.7/dist-packages (from sacrebleu>=1.4.12->fairseq==1.0.0a0+d6855ba) (2.0.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch->fairseq==1.0.0a0+d6855ba) (3.7.4.3)\n",
            "Requirement already satisfied: importlib-resources; python_version < \"3.9\" in /usr/local/lib/python3.7/dist-packages (from hydra-core<1.1->fairseq==1.0.0a0+d6855ba) (5.1.2)\n",
            "Collecting antlr4-python3-runtime==4.8\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/56/02/789a0bddf9c9b31b14c3e79ec22b9656185a803dc31c15f006f9855ece0d/antlr4-python3-runtime-4.8.tar.gz (112kB)\n",
            "\u001b[K     |████████████████████████████████| 112kB 8.5MB/s \n",
            "\u001b[?25hCollecting PyYAML>=5.1.*\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7a/a5/393c087efdc78091afa2af9f1378762f9821c9c1d7a22c5753fb5ac5f97a/PyYAML-5.4.1-cp37-cp37m-manylinux1_x86_64.whl (636kB)\n",
            "\u001b[K     |████████████████████████████████| 645kB 8.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi->fairseq==1.0.0a0+d6855ba) (2.20)\n",
            "Requirement already satisfied: zipp>=0.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-resources; python_version < \"3.9\"->hydra-core<1.1->fairseq==1.0.0a0+d6855ba) (3.4.1)\n",
            "Building wheels for collected packages: antlr4-python3-runtime\n",
            "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.8-cp37-none-any.whl size=141231 sha256=025503d5bd38e77954b78c6684197fe585be2867fdeb660bd743bc8a9861926d\n",
            "  Stored in directory: /root/.cache/pip/wheels/e3/e2/fa/b78480b448b8579ddf393bebd3f47ee23aa84c89b6a78285c8\n",
            "Successfully built antlr4-python3-runtime\n",
            "Installing collected packages: PyYAML, omegaconf, antlr4-python3-runtime, hydra-core, fairseq\n",
            "  Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "  Running setup.py develop for fairseq\n",
            "Successfully installed PyYAML-5.4.1 antlr4-python3-runtime-4.8 fairseq hydra-core-1.0.6 omegaconf-2.0.6\n",
            "/content/testing\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kKA8afhBawO5",
        "outputId": "c818e9e0-fc4b-43aa-ac65-c8af81d7f332"
      },
      "source": [
        "# download the indictrans model\n",
        "\n",
        "\n",
        "# downloading the en-indic model\n",
        "!wget https://akpublicdata.blob.core.windows.net/indicnlp/indictrans/inidctrans-en-indic-v0.2.zip\n",
        "!unzip inidctrans-en-indic-v0.2.zip\n",
        "\n",
        "# downloading the indic-en model\n",
        "!wget https://akpublicdata.blob.core.windows.net/indicnlp/indictrans/indictrans-indic-en-v0.2.zip\n",
        "!unzip indictrans-indic-en-v0.2.zip\n",
        "\n",
        "%cd indicTrans/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-04-30 18:33:50--  https://akpublicdata.blob.core.windows.net/indicnlp/indictrans/inidctrans-en-indic-v0.2.zip\n",
            "Resolving akpublicdata.blob.core.windows.net (akpublicdata.blob.core.windows.net)... 52.239.246.4\n",
            "Connecting to akpublicdata.blob.core.windows.net (akpublicdata.blob.core.windows.net)|52.239.246.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4609212103 (4.3G) [application/x-zip-compressed]\n",
            "Saving to: ‘inidctrans-en-indic-v0.2.zip’\n",
            "\n",
            "inidctrans-en-indic 100%[===================>]   4.29G  22.8MB/s    in 3m 56s  \n",
            "\n",
            "2021-04-30 18:37:46 (18.6 MB/s) - ‘inidctrans-en-indic-v0.2.zip’ saved [4609212103/4609212103]\n",
            "\n",
            "unzip:  cannot find or open en-indic.zip, en-indic.zip.zip or en-indic.zip.ZIP.\n",
            "/content/testing/indicTrans\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lg1sQFfyWJli"
      },
      "source": [
        "# creating a text file and adding en sentences we can use for testing the model\n",
        "!touch en_sentences.txt\n",
        "!echo 'This bicycle is too small for you !!' >> en_sentences.txt\n",
        "!echo \"I will directly meet you at the airport.\" >> en_sentences.txt\n",
        "!echo 'If COVID-19 is spreading in your community, stay safe by taking some simple precautions, such as physical distancing, wearing a mask, keeping rooms well ventilated, avoiding crowds, cleaning your hands, and coughing into a bent elbow or tissue' >> en_sentences.txt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fLg9BWAGWvLU",
        "outputId": "765e984f-1786-463e-f739-24c8ea4df8cd"
      },
      "source": [
        "# joint_translate takes src_file, output_fname, src_lang, tgt_lang, model_folder as inputs\n",
        "# src_file -> input text file to be translated\n",
        "# output_fname -> name of the output file (will get created) containing the model predictions\n",
        "# src_lang -> source lang code of the input text ( in this case we are using en-indic model and hence src_lang would be 'en')\n",
        "# tgt_lang -> target lang code of the input text ( tgt lang for en-indic model would be any of the 11 indic langs we trained on:\n",
        "#              as, bn, hi, gu, kn, ml, mr, or, pa, ta, te)\n",
        "# supported languages are:\n",
        "#              as - assamese, bn - bengali, gu - gujarathi, hi - hindi, kn - kannada, \n",
        "#              ml - malayalam, mr - marathi, or - oriya, pa - punjabi, ta - tamil, te - telugu\n",
        "\n",
        "# model_dir -> the directory containing the model and the vocab files\n",
        "\n",
        "# Note: if the translation is taking a lot of time, please tune the buffer_size and batch_size parameter for fairseq-interactive defined inside this joint_translate script\n",
        "\n",
        "\n",
        "# here we are translating the english sentences to tamil\n",
        "!bash joint_translate.sh en_sentences.txt ta_outputs.txt 'en' 'ta' '../en-indic'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fri Apr 30 20:10:42 UTC 2021\n",
            "Applying normalization and script conversion\n",
            "100% 3/3 [00:00<00:00, 50.90it/s]\n",
            "Number of sentences in input: 3\n",
            "Applying BPE\n",
            "Decoding\n",
            "Extracting translations, script conversion and detokenization\n",
            "Translation completed\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8QzkBCgeGZiH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bcf58965-b1b6-4379-e39e-31fea745f335"
      },
      "source": [
        "!cat ta_outputs.txt"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "இந்த சைக்கிள் உங்களுக்கு மிகவும் சிறியது!\n",
            "விமான நிலையத்தில் உங்களை நேரில் சந்திக்கிறேன்.\n",
            "உங்கள் சமூகத்தில் கோவிட்-19 பரவுகிறது என்றால், சில எளிய முன்னெச்சரிக்கை நடவடிக்கைகளான, தனி நபர் இடைவெளி, முகக்கவசம் அணிதல், அறைகளை நன்கு காற்றோட்டமாக வைத்திருத்தல், கூட்டத்தைத் தவிர்த்தல், கைகளைக் கழுவுதல், முழங்கை அல்லது திசுக்களில் இருமல் போன்றவற்றை மேற்கொள்வதன் மூலம் பாதுகாப்பாக இருங்கள்.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c4v9BmbZao5d",
        "outputId": "935ac68d-5805-4919-9a2b-1bd48bb49ff4"
      },
      "source": [
        "# Similarly, we can translate the english sentences to hindi\n",
        "!bash joint_translate.sh en_sentences.txt hi_outputs.txt 'en' 'hi' '../en-indic'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fri Apr 30 20:13:36 UTC 2021\n",
            "Applying normalization and script conversion\n",
            "100% 3/3 [00:00<00:00, 53.30it/s]\n",
            "Number of sentences in input: 3\n",
            "Applying BPE\n",
            "Decoding\n",
            "Extracting translations, script conversion and detokenization\n",
            "Translation completed\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pNNzyR_LfqIr",
        "outputId": "6f13c5dc-f9c6-4365-8569-2a80a7773925"
      },
      "source": [
        "!cat hi_outputs.txt"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "यह साइकिल तुम्हारे लिए बहुत छोटी है!\n",
            "मैं आपसे एयरपोर्ट पर ही मिलने वाला हूं।\n",
            "यदि आपके समुदाय में कोविड-19 फैल रहा है, तो कुछ सरल सावधानियां बरतें, जैसे शारीरिक दूरी बनाए रखना, मास्क पहनना, कमरों को अच्छी तरह से हवादार रखना, भीड़ से बचना, अपने हाथों को साफ करना और कोहनी या ऊतक को मोड़कर खांसते हुए सुरक्षित रहें\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PzjbDLBtaol9"
      },
      "source": [
        "# creating a text file and adding hi sentences we can use for testing the model\n",
        "!touch hi_sentences.txt\n",
        "!echo 'तुम आज सुबह यहाँ क्यों आए?' >> hi_sentences.txt\n",
        "!echo \"मेरे परिवार में हर कोई जल्दी उठता है।\" >> hi_sentences.txt\n",
        "!echo ' स्वास्थ्य और परिवार कल्याण मंत्रालय द्वारा प्रदान की गई जानकारी और सलाह को सावधानी व सही तरीके से पालन कर वायरस के स्थानीय प्रसार को रोका जा सकता है।' >> hi_sentences.txt\n",
        "\n",
        "!touch ta_sentences.txt\n",
        "!echo 'அவனுக்கு நம்மைப் தெரியும் என்று தோன்றுகிறது' >> ta_sentences.txt\n",
        "!echo \"இது எங்கே இருக்கு என்று என்னால் கண்டுபிடிக்க முடியவில்லை.\" >> ta_sentences.txt\n",
        "!echo 'உங்களுக்கு உங்கள் அருகில் இருக்கும் ஒருவருக்கோ இத்தகைய அறிகுறிகள் தென்பட்டால், வீட்டிலேயே இருப்பது, கொரோனா வைரஸ் தொற்று பிறருக்கு வராமல் தடுக்க உதவும்.' >> ta_sentences.txt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5uaOmKb8gmeN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3a8a756c-5ecc-4099-fc53-33b6b36be3ed"
      },
      "source": [
        "# here we are translating the english sentences to hindi\n",
        "!bash joint_translate.sh hi_sentences.txt en_outputs.txt 'hi' 'en' '../indic-en'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fri Apr 30 20:59:01 UTC 2021\n",
            "Applying normalization and script conversion\n",
            "100% 3/3 [00:00<00:00, 58.65it/s]\n",
            "Number of sentences in input: 3\n",
            "Applying BPE\n",
            "Decoding\n",
            "Extracting translations, script conversion and detokenization\n",
            "Translation completed\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iLD7WPqmlSnC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8d75cd59-7dc6-47cf-c289-13578885af41"
      },
      "source": [
        "! cat en_outputs.txt"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Why did you come here this morning?\n",
            "Everyone in my family gets up early.\n",
            "The local spread of the virus can be curbed by following the information and advice provided by the Ministry of Health and Family Welfare in a careful and correct manner.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O3mJyj-QljWz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "67233853-8c67-4cc7-dad1-a722e083a147"
      },
      "source": [
        "# here we are translating the english sentences to tamil\n",
        "!bash joint_translate.sh ta_sentences.txt en_outputs.txt 'ta' 'en' '../indic-en'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fri Apr 30 21:06:20 UTC 2021\n",
            "Applying normalization and script conversion\n",
            "100% 3/3 [00:00<00:00, 41.32it/s]\n",
            "Number of sentences in input: 3\n",
            "Applying BPE\n",
            "Decoding\n",
            "Extracting translations, script conversion and detokenization\n",
            "Translation completed\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GapEJESiloD8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7b69f768-f9e4-4799-8555-fc4717bbd0aa"
      },
      "source": [
        "! cat en_outputs.txt"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "He seems to know us.\n",
            "I couldnt find it anywhere.\n",
            "If someone in your neighbourhood develops these symptoms, staying at home can help prevent the spread of the coronavirus infection.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-xcnDOc4gNKC"
      },
      "source": [
        "# to compute bleu scores for the predicitions with a reference file, use the following command\n",
        "\n",
        "# bash compute_bleu.sh pred_fname ref_fname src_lang tgt_lang\n",
        "# arguments:\n",
        "# pred_fname: file that contains model predictions\n",
        "# ref_fname: file that contains references\n",
        "# src_lang and tgt_lang : the source and target language"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9YK2BdwvrUgI"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}